Assignment -2 COMP 6651- Fall 2022Algorithm Design TechniquesSubmitted To:Dr. Denis PankratovSubmitted by:1. (a) COMP 6651: Solutions to Assignment 2 Fall 2022Submission through Moodle is due by October 16th at 23:55 Claim: If f1 > Pni=2 fi then character 1 receives codeword of length 1 in Huffman coding problem. Proof by induction on n:Base case n = 2: in this case both characters receive codewords of length 1, so the claim is trivially true. Inductive assumption: assume that for all inputs with n ≥ 2 characters such that f1 > Pni=2 fi character 1 receives codeword of length 1 in Huffman coding problem. Inductive step: suppose we are given n + 1 characters with frequencies satisfying f1 > Pn+1 fi. i=2 The first step of the Huffman algorithm is that it merges the two characters of lower frequencies together. These two characters cannot be character 1, since we have at least three characters in total (i.e., n+1 ≥ 3) and f1 has highest frequency. Without loss of generality assume that lowest frequency characters are f and f (otherwise, we can reindex the characters). Let f?? denote n n+1 i the new frequencies after the merge operation. That is, we have f?? = f for i ? {1,2,...,n?1} ii and f?? = f + f . Observe that the new frequencies satisfy the inductive assumption, that n n n+1 is, f?? > Pn f??, since Pn f?? = Pn+1 f and f?? = f . Thus, by inductive assumption, the 1i=2i i=2ii=2i11 optimal solution to the new frequencies assigns character 1 codeword of length 1. According to Huffman’s algorithm, the solution to the original problem is obtained from the solution to the new frequencies by expanding the node corresponding to f?? to have two children corresponding n to frequencies fn and fn+1. Clearly, this does not affect the codewords of characters 1,...,n?1. Thus, if character 1 had codeword of length 1 in the solution to the new frequencies, then it also has codeword of length 1 in the solution to the original frequencies. The claim is TRUE. Suppose for contradiction that x is a character with codeword of length 1. Then during the second to last iteration of Huffman’s algorithm, the priority queue must have contents: f?? ≤ f?? ≤ f , abx where a and b are subtrees containing all the other characters (note that if we have f?? ≤ f ≤ f?? axb or f ≤ f?? ≤ f?? then x will be merged into subtree a and won’t get codeword of length 1). Since xab 2. (a) The input is given as an array of reals A[1..n]. First, sort the input points in non-decreasing order. Thus, we have A[1] ≤ A[2] ≤ · · · ≤ A[n] after the sorting operation. Pick the first point A[1] and include the interval [A[1], A[1] + 1] into the solution. Disregard the points covered by this interval, and repeat the procedure by picking the next uncovered point and introducing the unit length interval with that point as the leftmost point of the interval. Continue, until all the points are covered. (b) f < (1/3)Pn f it means that f??,f?? < (1/3)Pn f and f?? +f?? +f < (1/3)Pn f + x j=1j ab j=1j abx j=1j (1/3) Pnj =1 fj + (1/3) Pnj =1 fj = Pnj =1 fj , so the sum of all frequencies of characters is strictly less than Pnj=1 fj, which is a contradiction. (b) procedure CoverPoints(A[1..n]) Sort A in non-decreasing order Initialize solution set of intervals S ? ? i ? 1while i ≤ n do S ? S ? {[A[i], A[i] + 1]}while i + 1 ≤ n and A[i + 1] ≤ A[i] + 1 do i?i+1 i?i+1 return S ? keeps track of the next uncovered point 3. (c) For the following proof suppose that the input array is already sorted A[1] ≤ A[2] ≤ · · · ≤ A[n]. We use the standard greedy loop invariant. Let Si denote the solution obtained by greedy on the first i entries of the array A. (LI): Si can be extended to an optimal solution to the overall instance. Proof by induction on i: Base case i = 0: The solution set S0 is empty and an empty solution can be extended to an optimal solution to the overall instance. Inductive assumption: Assume that for some i ≥ 0 the partial greedy solution Si can be extended to some optimal solution OPT to the overall instance. Inductive step: Consider the partial greedy solution Si+1 on the first i+1 elements. We consider the different cases: Case 1: A[i+1] is covered by one of the intervals in Si. Then Si+1 = Si, by inductive assumption Si can be extended to OPT, therefore so can Si+1. Case 2: A[i + 1] is not covered by one of the intervals in Si. Thus, Si+1 = Si ? {[A[i + 1], A[i + 1]+1]}. Since extension of Si to an optimal solution OPT must cover point A[i+1] and none of the intervals in Si cover A[i+1], there must be some interval I ? OPT such that A[i+1] ? I. If I = [A[i+1],A[i+1]+1] then OPT is also an extension of Si+1 and we are done. If I = [r,r+1] is some other interval covering point A[i + 1], then we can replace it to define a new extension OPT = (OPT \ {I}) ? {[A[i + 1],A[i + 1] + 1]}. We claim that OPT is an optimal extension ]] of S . First observe that |OPT| = |OPT|, thus, the number of intervals in OPT is optimal. i+1 ]] Moreover, we can see that intervals in OPT must cover all the points, since the points A[1..i] ] ] are covered by S and S ? OPT. Moreover, if some point A[j] with j ≥ i + 1 was covered by ii I in OPT then it is covered by [A[i + 1],A[i + 1] + 1] in OPT. Since A[j] being covered by I with j ≥ i+1 implies that A[i+1] < A[j] < r+1 < A[i+1]+1, due to ordering of points and algorithm selecting the rightmost unit-length interval covering A[i + 1]. (d) The sorting operation can be done with MergeSort, for example, in time O(nlogn). The while loop iterates over the array A and does constant amount of work per each entry in A. Thus, the entire amount of work done by the outer while loop is O(n). The overall running time is dominated by the sorting operation and is, therefore, O(n log n). (a) Consider the input with 3 clients located on the line at positions p1 = 1, p2 = 3, p3 = 4. Since clients are located on the line, we have dist[i, j] = |pi ? pj |. Consider the request sequence: p2, p3, p2, p3, p2, p3. The greedy algorithm relocates one of the consultants from p1 to p2 at cost 2 and then this consultant is always the closest for all future requests to p2 and p3 incurring cost 1 for each subsequence request. Thus, the overall cost is 2 + 5 = 7. If, instead, we relocate consultant 1 to process p2 and then consultant 2 to process p3, this initially incurs cost ] (e) (f) 4. (a) the optimal solution, we minimize over the three choices.The optimality of these recursive steps can be seen from the cut-and-paste property. We assume that the requests are given in the array R[1..n] of indices of locations. In the notation above, it means that R[j] = r?? . The dynamic programming table is of size k3n and each entry takes constant time to fill in. Thus, the overall running time is O(k3n). Input: array of integers M[1..k] describing motion sickness of types of segments; array of non-negative integers E[1..k] describing excitement of types of segments; non-negative integer n. (b) 2 + 3 = 5, but all the future requests to p2 and p3 are processed for free. Thus, greedy solution is not optimal. The dynamic programming table is indexed by two indices: first index is a triple (i1, i2, i3) with i1, i2, i3 ? {1, 2, . . . , k} which indicate that consultants are present at locations pi1 , pi2 , pi3 , and the second index is j which indicates the prefix of the request sequence. The semantic array is defined as follows: D[(i1, i2, i3), j] = the cheapest way of processing requests r1, r2, . . . , rj with the three consultants beginning at p1 and ending at locations pi1 , pi2 , pi3 , respectively.The overall answer to the problem is stored in min1≤i1,i2,i3≤k D[(i1, i2, i3), n]. While request r refers to the location of some client, we use notation r?? to refer to the index of jj theclientr,i.e.,ifr =p thenr?? =l. jjlj Base case is when j = 0 then D[(i1, i2, i3), 0] = dist[1, i1] + dist[1, i2] + dist[1, i3] for all i1, i2, i3 ? {1,...,k}.The general case is for j ≥ 1 then we have:If rj is one of the pi1 , pi2 , pi3 then D[(i1, i2, i3), j] = D[(i1, i2, i3), j ? 1]. Otherwise, (c) (d) What is the cheapest way of D[(i ,r??,i ),j?1]+dist[r??,i ], 1j3 j2 D[(i ,i ,r??),j?1]+dist[r??,i ]). 12j j3 processing r1, . . . , rj with consultants ending up atmust travel D[(i ,i ,i ),j]=min(D[(r??,i ,i ),j?1]+dist[r??,i ], 123 j23 j1 pi1 , pi2 , pi3 ? When j = 0 then this is equivalent to saying that the consultants to pi1 , pi2 , pi3 from their initial locations 1, 1, 1. The cost of doing it is dist[1, i1] + dist[1, i2] + dist[1,i3], so this explains the base case. When j > 0 then there are two cases. Case 1: when rj is one of the locations pi1 , pi2 , pi3 . Then we can take the cheapest way of processing requests r1, r2, . . . , rj?1 and consultants ending up in pi1 , pi2 , pi3 and then the request rj is processed for free since we already have a consultant there. Case 2: when rj is not one of the locations pi1 , pi2 , pi3 . Suppose that consultant 1 was responsible for processing rj in the cheapest solution to the subproblem. It means that prior to relocating to pi1 the consultant was at rj to process that request. Thus, the optimal solution consists of processing requests r1, r2, . . . , rj?1 and ending in positions (rj , pi2 , pi3 ), processing request rj , and thenrelocatingconsultant1top . ThecostofthisisgivenbyD[(r??,i ,i ),j?1]+dist[r??,i ]. i1 j23 j1 Similar expressions are obtained when consultant 2 or consultant 3 is responsible for processing rj. Since we do not know a priori which of the consultants is responsible for processing rj in j locations procedure MinimizeTravelCost(dist[1..k][1..k],R[1..n]) Initialize array D[1...k, 1..k, 1..k, 0..n]fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo D[i1, i2, i3, 0] ? dist[1, i1] + dist[1, i2] + dist[1, i3] for j = 1 to n do fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo if R[j]=i1 orR[j]=i2 orR[j]=i3 then D[i1, i2, i3, j] ? D[i1, i2, i3, j ? 1] else D[i1, i2, i3, j] ? min(D[R[j], i2, i3, j dist[R[j], i2], D[i1, i2, R[j], j ? 1] + dist[R[j], i3]) r?∞fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo r ? min(r, D[i1, i2, i3, n]) return r ? 1] + dist[R[j], i1], D[i1, R[j], i3, j ? 1] + Output: maximum total excitement obtainable by a roller coaster consisting of n segments with motion sickness between 0 and 100 at all times. If such a roller coaster is impossible, the output is ?∞. (b) The array is indexed by two indices: i ? {0,1,...,n} and m ? {0,1,2,...,100}. D[i, m] = maximum total excitement of a roller coaster consisting of i segments with motion sickness between 0 and 100 at all times andexactly m at the end of i segments The overall answer is given by max0≤m≤100 D[n, m]. (c) D[0, 0] = 0 D[0,m] = ?∞ for m ? {1,...,100} D[i, m] = max D[i ? 1, m ? M[j]] + E[j] j?[k]:0≤m?M[j]≤100 Where the max returns ?∞ if there is no index j such that 0 ≤ m ? M[j] ≤ 100. 4. (d)  Maximum excitement roller-coaster of length i with motion sickness m at the end (if it can be built) contains some segment of type j as the last segment and a maximum excitement roller- coaster of length i ? 1 with motion sickness m ? M[j] at the end (by cut-and paste property). The last segment then gives excitement E[j] and the excitement accumulated by the first i ? 1 segments is given by D[i ? 1, m ? M[j]]. Since we do not know the value of j a priori, we optimize over all choices of j that are feasible, i.e., maintain motion sickness between 0 and 100. 5. (e)  The array contains O(n) entries, and each entry takes O(k) time to fill in. Thus, the overall running time would be O(nk). 1. (a) COMP 6651: Solutions to Assignment 2 Fall 2022Submission through Moodle is due by October 16th at 23:55 Claim: If f1 > Pni=2 fi then character 1 receives codeword of length 1 in Huffman coding problem. Proof by induction on n:Base case n = 2: in this case both characters receive codewords of length 1, so the claim is trivially true. Inductive assumption: assume that for all inputs with n ≥ 2 characters such that f1 > Pni=2 fi character 1 receives codeword of length 1 in Huffman coding problem. Inductive step: suppose we are given n + 1 characters with frequencies satisfying f1 > Pn+1 fi. i=2 The first step of the Huffman algorithm is that it merges the two characters of lower frequencies together. These two characters cannot be character 1, since we have at least three characters in total (i.e., n+1 ≥ 3) and f1 has highest frequency. Without loss of generality assume that lowest frequency characters are f and f (otherwise, we can reindex the characters). Let f?? denote n n+1 i the new frequencies after the merge operation. That is, we have f?? = f for i ? {1,2,...,n?1} ii and f?? = f + f . Observe that the new frequencies satisfy the inductive assumption, that n n n+1 is, f?? > Pn f??, since Pn f?? = Pn+1 f and f?? = f . Thus, by inductive assumption, the 1i=2i i=2ii=2i11 optimal solution to the new frequencies assigns character 1 codeword of length 1. According to Huffman’s algorithm, the solution to the original problem is obtained from the solution to the new frequencies by expanding the node corresponding to f?? to have two children corresponding n to frequencies fn and fn+1. Clearly, this does not affect the codewords of characters 1,...,n?1. Thus, if character 1 had codeword of length 1 in the solution to the new frequencies, then it also has codeword of length 1 in the solution to the original frequencies. The claim is TRUE. Suppose for contradiction that x is a character with codeword of length 1. Then during the second to last iteration of Huffman’s algorithm, the priority queue must have contents: f?? ≤ f?? ≤ f , abx where a and b are subtrees containing all the other characters (note that if we have f?? ≤ f ≤ f?? axb or f ≤ f?? ≤ f?? then x will be merged into subtree a and won’t get codeword of length 1). Since xab 2. (a) The input is given as an array of reals A[1..n]. First, sort the input points in non-decreasing order. Thus, we have A[1] ≤ A[2] ≤ · · · ≤ A[n] after the sorting operation. Pick the first point A[1] and include the interval [A[1], A[1] + 1] into the solution. Disregard the points covered by this interval, and repeat the procedure by picking the next uncovered point and introducing the unit length interval with that point as the leftmost point of the interval. Continue, until all the points are covered. (b) f < (1/3)Pn f it means that f??,f?? < (1/3)Pn f and f?? +f?? +f < (1/3)Pn f + x j=1j ab j=1j abx j=1j (1/3) Pnj =1 fj + (1/3) Pnj =1 fj = Pnj =1 fj , so the sum of all frequencies of characters is strictly less than Pnj=1 fj, which is a contradiction. (b) procedure CoverPoints(A[1..n]) Sort A in non-decreasing order Initialize solution set of intervals S ? ? i ? 1while i ≤ n do S ? S ? {[A[i], A[i] + 1]}while i + 1 ≤ n and A[i + 1] ≤ A[i] + 1 do i?i+1 i?i+1 return S ? keeps track of the next uncovered point 3. (c) For the following proof suppose that the input array is already sorted A[1] ≤ A[2] ≤ · · · ≤ A[n]. We use the standard greedy loop invariant. Let Si denote the solution obtained by greedy on the first i entries of the array A. (LI): Si can be extended to an optimal solution to the overall instance. Proof by induction on i: Base case i = 0: The solution set S0 is empty and an empty solution can be extended to an optimal solution to the overall instance. Inductive assumption: Assume that for some i ≥ 0 the partial greedy solution Si can be extended to some optimal solution OPT to the overall instance. Inductive step: Consider the partial greedy solution Si+1 on the first i+1 elements. We consider the different cases: Case 1: A[i+1] is covered by one of the intervals in Si. Then Si+1 = Si, by inductive assumption Si can be extended to OPT, therefore so can Si+1. Case 2: A[i + 1] is not covered by one of the intervals in Si. Thus, Si+1 = Si ? {[A[i + 1], A[i + 1]+1]}. Since extension of Si to an optimal solution OPT must cover point A[i+1] and none of the intervals in Si cover A[i+1], there must be some interval I ? OPT such that A[i+1] ? I. If I = [A[i+1],A[i+1]+1] then OPT is also an extension of Si+1 and we are done. If I = [r,r+1] is some other interval covering point A[i + 1], then we can replace it to define a new extension OPT = (OPT \ {I}) ? {[A[i + 1],A[i + 1] + 1]}. We claim that OPT is an optimal extension ]] of S . First observe that |OPT| = |OPT|, thus, the number of intervals in OPT is optimal. i+1 ]] Moreover, we can see that intervals in OPT must cover all the points, since the points A[1..i] ] ] are covered by S and S ? OPT. Moreover, if some point A[j] with j ≥ i + 1 was covered by ii I in OPT then it is covered by [A[i + 1],A[i + 1] + 1] in OPT. Since A[j] being covered by I with j ≥ i+1 implies that A[i+1] < A[j] < r+1 < A[i+1]+1, due to ordering of points and algorithm selecting the rightmost unit-length interval covering A[i + 1]. (d) The sorting operation can be done with MergeSort, for example, in time O(nlogn). The while loop iterates over the array A and does constant amount of work per each entry in A. Thus, the entire amount of work done by the outer while loop is O(n). The overall running time is dominated by the sorting operation and is, therefore, O(n log n). (a) Consider the input with 3 clients located on the line at positions p1 = 1, p2 = 3, p3 = 4. Since clients are located on the line, we have dist[i, j] = |pi ? pj |. Consider the request sequence: p2, p3, p2, p3, p2, p3. The greedy algorithm relocates one of the consultants from p1 to p2 at cost 2 and then this consultant is always the closest for all future requests to p2 and p3 incurring cost 1 for each subsequence request. Thus, the overall cost is 2 + 5 = 7. If, instead, we relocate consultant 1 to process p2 and then consultant 2 to process p3, this initially incurs cost ] (e) (f) 4. (a) the optimal solution, we minimize over the three choices.The optimality of these recursive steps can be seen from the cut-and-paste property. We assume that the requests are given in the array R[1..n] of indices of locations. In the notation above, it means that R[j] = r?? . The dynamic programming table is of size k3n and each entry takes constant time to fill in. Thus, the overall running time is O(k3n). Input: array of integers M[1..k] describing motion sickness of types of segments; array of non-negative integers E[1..k] describing excitement of types of segments; non-negative integer n. (b) 2 + 3 = 5, but all the future requests to p2 and p3 are processed for free. Thus, greedy solution is not optimal. The dynamic programming table is indexed by two indices: first index is a triple (i1, i2, i3) with i1, i2, i3 ? {1, 2, . . . , k} which indicate that consultants are present at locations pi1 , pi2 , pi3 , and the second index is j which indicates the prefix of the request sequence. The semantic array is defined as follows: D[(i1, i2, i3), j] = the cheapest way of processing requests r1, r2, . . . , rj with the three consultants beginning at p1 and ending at locations pi1 , pi2 , pi3 , respectively.The overall answer to the problem is stored in min1≤i1,i2,i3≤k D[(i1, i2, i3), n]. While request r refers to the location of some client, we use notation r?? to refer to the index of jj theclientr,i.e.,ifr =p thenr?? =l. jjlj Base case is when j = 0 then D[(i1, i2, i3), 0] = dist[1, i1] + dist[1, i2] + dist[1, i3] for all i1, i2, i3 ? {1,...,k}.The general case is for j ≥ 1 then we have:If rj is one of the pi1 , pi2 , pi3 then D[(i1, i2, i3), j] = D[(i1, i2, i3), j ? 1]. Otherwise, (c) (d) What is the cheapest way of D[(i ,r??,i ),j?1]+dist[r??,i ], 1j3 j2 D[(i ,i ,r??),j?1]+dist[r??,i ]). 12j j3 processing r1, . . . , rj with consultants ending up atmust travel D[(i ,i ,i ),j]=min(D[(r??,i ,i ),j?1]+dist[r??,i ], 123 j23 j1 pi1 , pi2 , pi3 ? When j = 0 then this is equivalent to saying that the consultants to pi1 , pi2 , pi3 from their initial locations 1, 1, 1. The cost of doing it is dist[1, i1] + dist[1, i2] + dist[1,i3], so this explains the base case. When j > 0 then there are two cases. Case 1: when rj is one of the locations pi1 , pi2 , pi3 . Then we can take the cheapest way of processing requests r1, r2, . . . , rj?1 and consultants ending up in pi1 , pi2 , pi3 and then the request rj is processed for free since we already have a consultant there. Case 2: when rj is not one of the locations pi1 , pi2 , pi3 . Suppose that consultant 1 was responsible for processing rj in the cheapest solution to the subproblem. It means that prior to relocating to pi1 the consultant was at rj to process that request. Thus, the optimal solution consists of processing requests r1, r2, . . . , rj?1 and ending in positions (rj , pi2 , pi3 ), processing request rj , and thenrelocatingconsultant1top . ThecostofthisisgivenbyD[(r??,i ,i ),j?1]+dist[r??,i ]. i1 j23 j1 Similar expressions are obtained when consultant 2 or consultant 3 is responsible for processing rj. Since we do not know a priori which of the consultants is responsible for processing rj in j locations procedure MinimizeTravelCost(dist[1..k][1..k],R[1..n]) Initialize array D[1...k, 1..k, 1..k, 0..n]fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo D[i1, i2, i3, 0] ? dist[1, i1] + dist[1, i2] + dist[1, i3] for j = 1 to n do fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo if R[j]=i1 orR[j]=i2 orR[j]=i3 then D[i1, i2, i3, j] ? D[i1, i2, i3, j ? 1] else D[i1, i2, i3, j] ? min(D[R[j], i2, i3, j dist[R[j], i2], D[i1, i2, R[j], j ? 1] + dist[R[j], i3]) r?∞fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo r ? min(r, D[i1, i2, i3, n]) return r ? 1] + dist[R[j], i1], D[i1, R[j], i3, j ? 1] + Output: maximum total excitement obtainable by a roller coaster consisting of n segments with motion sickness between 0 and 100 at all times. If such a roller coaster is impossible, the output is ?∞. (b) The array is indexed by two indices: i ? {0,1,...,n} and m ? {0,1,2,...,100}. D[i, m] = maximum total excitement of a roller coaster consisting of i segments with motion sickness between 0 and 100 at all times andexactly m at the end of i segments The overall answer is given by max0≤m≤100 D[n, m]. (c) D[0, 0] = 0 D[0,m] = ?∞ for m ? {1,...,100} D[i, m] = max D[i ? 1, m ? M[j]] + E[j] j?[k]:0≤m?M[j]≤100 Where the max returns ?∞ if there is no index j such that 0 ≤ m ? M[j] ≤ 100. 4. (d)  Maximum excitement roller-coaster of length i with motion sickness m at the end (if it can be built) contains some segment of type j as the last segment and a maximum excitement roller- coaster of length i ? 1 with motion sickness m ? M[j] at the end (by cut-and paste property). The last segment then gives excitement E[j] and the excitement accumulated by the first i ? 1 segments is given by D[i ? 1, m ? M[j]]. Since we do not know the value of j a priori, we optimize over all choices of j that are feasible, i.e., maintain motion sickness between 0 and 100. 5. (e)  The array contains O(n) entries, and each entry takes O(k) time to fill in. Thus, the overall running time would be O(nk). 1. (a) COMP 6651: Solutions to Assignment 2 Fall 2022Submission through Moodle is due by October 16th at 23:55 Claim: If f1 > Pni=2 fi then character 1 receives codeword of length 1 in Huffman coding problem. Proof by induction on n:Base case n = 2: in this case both characters receive codewords of length 1, so the claim is trivially true. Inductive assumption: assume that for all inputs with n ≥ 2 characters such that f1 > Pni=2 fi character 1 receives codeword of length 1 in Huffman coding problem. Inductive step: suppose we are given n + 1 characters with frequencies satisfying f1 > Pn+1 fi. i=2 The first step of the Huffman algorithm is that it merges the two characters of lower frequencies together. These two characters cannot be character 1, since we have at least three characters in total (i.e., n+1 ≥ 3) and f1 has highest frequency. Without loss of generality assume that lowest frequency characters are f and f (otherwise, we can reindex the characters). Let f?? denote n n+1 i the new frequencies after the merge operation. That is, we have f?? = f for i ? {1,2,...,n?1} ii and f?? = f + f . Observe that the new frequencies satisfy the inductive assumption, that n n n+1 is, f?? > Pn f??, since Pn f?? = Pn+1 f and f?? = f . Thus, by inductive assumption, the 1i=2i i=2ii=2i11 optimal solution to the new frequencies assigns character 1 codeword of length 1. According to Huffman’s algorithm, the solution to the original problem is obtained from the solution to the new frequencies by expanding the node corresponding to f?? to have two children corresponding n to frequencies fn and fn+1. Clearly, this does not affect the codewords of characters 1,...,n?1. Thus, if character 1 had codeword of length 1 in the solution to the new frequencies, then it also has codeword of length 1 in the solution to the original frequencies. The claim is TRUE. Suppose for contradiction that x is a character with codeword of length 1. Then during the second to last iteration of Huffman’s algorithm, the priority queue must have contents: f?? ≤ f?? ≤ f , abx where a and b are subtrees containing all the other characters (note that if we have f?? ≤ f ≤ f?? axb or f ≤ f?? ≤ f?? then x will be merged into subtree a and won’t get codeword of length 1). Since xab 2. (a) The input is given as an array of reals A[1..n]. First, sort the input points in non-decreasing order. Thus, we have A[1] ≤ A[2] ≤ · · · ≤ A[n] after the sorting operation. Pick the first point A[1] and include the interval [A[1], A[1] + 1] into the solution. Disregard the points covered by this interval, and repeat the procedure by picking the next uncovered point and introducing the unit length interval with that point as the leftmost point of the interval. Continue, until all the points are covered. (b) f < (1/3)Pn f it means that f??,f?? < (1/3)Pn f and f?? +f?? +f < (1/3)Pn f + x j=1j ab j=1j abx j=1j (1/3) Pnj =1 fj + (1/3) Pnj =1 fj = Pnj =1 fj , so the sum of all frequencies of characters is strictly less than Pnj=1 fj, which is a contradiction. (b) procedure CoverPoints(A[1..n]) Sort A in non-decreasing order Initialize solution set of intervals S ? ? i ? 1while i ≤ n do S ? S ? {[A[i], A[i] + 1]}while i + 1 ≤ n and A[i + 1] ≤ A[i] + 1 do i?i+1 i?i+1 return S ? keeps track of the next uncovered point 3. (c) For the following proof suppose that the input array is already sorted A[1] ≤ A[2] ≤ · · · ≤ A[n]. We use the standard greedy loop invariant. Let Si denote the solution obtained by greedy on the first i entries of the array A. (LI): Si can be extended to an optimal solution to the overall instance. Proof by induction on i: Base case i = 0: The solution set S0 is empty and an empty solution can be extended to an optimal solution to the overall instance. Inductive assumption: Assume that for some i ≥ 0 the partial greedy solution Si can be extended to some optimal solution OPT to the overall instance. Inductive step: Consider the partial greedy solution Si+1 on the first i+1 elements. We consider the different cases: Case 1: A[i+1] is covered by one of the intervals in Si. Then Si+1 = Si, by inductive assumption Si can be extended to OPT, therefore so can Si+1. Case 2: A[i + 1] is not covered by one of the intervals in Si. Thus, Si+1 = Si ? {[A[i + 1], A[i + 1]+1]}. Since extension of Si to an optimal solution OPT must cover point A[i+1] and none of the intervals in Si cover A[i+1], there must be some interval I ? OPT such that A[i+1] ? I. If I = [A[i+1],A[i+1]+1] then OPT is also an extension of Si+1 and we are done. If I = [r,r+1] is some other interval covering point A[i + 1], then we can replace it to define a new extension OPT = (OPT \ {I}) ? {[A[i + 1],A[i + 1] + 1]}. We claim that OPT is an optimal extension ]] of S . First observe that |OPT| = |OPT|, thus, the number of intervals in OPT is optimal. i+1 ]] Moreover, we can see that intervals in OPT must cover all the points, since the points A[1..i] ] ] are covered by S and S ? OPT. Moreover, if some point A[j] with j ≥ i + 1 was covered by ii I in OPT then it is covered by [A[i + 1],A[i + 1] + 1] in OPT. Since A[j] being covered by I with j ≥ i+1 implies that A[i+1] < A[j] < r+1 < A[i+1]+1, due to ordering of points and algorithm selecting the rightmost unit-length interval covering A[i + 1]. (d) The sorting operation can be done with MergeSort, for example, in time O(nlogn). The while loop iterates over the array A and does constant amount of work per each entry in A. Thus, the entire amount of work done by the outer while loop is O(n). The overall running time is dominated by the sorting operation and is, therefore, O(n log n). (a) Consider the input with 3 clients located on the line at positions p1 = 1, p2 = 3, p3 = 4. Since clients are located on the line, we have dist[i, j] = |pi ? pj |. Consider the request sequence: p2, p3, p2, p3, p2, p3. The greedy algorithm relocates one of the consultants from p1 to p2 at cost 2 and then this consultant is always the closest for all future requests to p2 and p3 incurring cost 1 for each subsequence request. Thus, the overall cost is 2 + 5 = 7. If, instead, we relocate consultant 1 to process p2 and then consultant 2 to process p3, this initially incurs cost ] (e) (f) 4. (a) the optimal solution, we minimize over the three choices.The optimality of these recursive steps can be seen from the cut-and-paste property. We assume that the requests are given in the array R[1..n] of indices of locations. In the notation above, it means that R[j] = r?? . The dynamic programming table is of size k3n and each entry takes constant time to fill in. Thus, the overall running time is O(k3n). Input: array of integers M[1..k] describing motion sickness of types of segments; array of non-negative integers E[1..k] describing excitement of types of segments; non-negative integer n. (b) 2 + 3 = 5, but all the future requests to p2 and p3 are processed for free. Thus, greedy solution is not optimal. The dynamic programming table is indexed by two indices: first index is a triple (i1, i2, i3) with i1, i2, i3 ? {1, 2, . . . , k} which indicate that consultants are present at locations pi1 , pi2 , pi3 , and the second index is j which indicates the prefix of the request sequence. The semantic array is defined as follows: D[(i1, i2, i3), j] = the cheapest way of processing requests r1, r2, . . . , rj with the three consultants beginning at p1 and ending at locations pi1 , pi2 , pi3 , respectively.The overall answer to the problem is stored in min1≤i1,i2,i3≤k D[(i1, i2, i3), n]. While request r refers to the location of some client, we use notation r?? to refer to the index of jj theclientr,i.e.,ifr =p thenr?? =l. jjlj Base case is when j = 0 then D[(i1, i2, i3), 0] = dist[1, i1] + dist[1, i2] + dist[1, i3] for all i1, i2, i3 ? {1,...,k}.The general case is for j ≥ 1 then we have:If rj is one of the pi1 , pi2 , pi3 then D[(i1, i2, i3), j] = D[(i1, i2, i3), j ? 1]. Otherwise, (c) (d) What is the cheapest way of D[(i ,r??,i ),j?1]+dist[r??,i ], 1j3 j2 D[(i ,i ,r??),j?1]+dist[r??,i ]). 12j j3 processing r1, . . . , rj with consultants ending up atmust travel D[(i ,i ,i ),j]=min(D[(r??,i ,i ),j?1]+dist[r??,i ], 123 j23 j1 pi1 , pi2 , pi3 ? When j = 0 then this is equivalent to saying that the consultants to pi1 , pi2 , pi3 from their initial locations 1, 1, 1. The cost of doing it is dist[1, i1] + dist[1, i2] + dist[1,i3], so this explains the base case. When j > 0 then there are two cases. Case 1: when rj is one of the locations pi1 , pi2 , pi3 . Then we can take the cheapest way of processing requests r1, r2, . . . , rj?1 and consultants ending up in pi1 , pi2 , pi3 and then the request rj is processed for free since we already have a consultant there. Case 2: when rj is not one of the locations pi1 , pi2 , pi3 . Suppose that consultant 1 was responsible for processing rj in the cheapest solution to the subproblem. It means that prior to relocating to pi1 the consultant was at rj to process that request. Thus, the optimal solution consists of processing requests r1, r2, . . . , rj?1 and ending in positions (rj , pi2 , pi3 ), processing request rj , and thenrelocatingconsultant1top . ThecostofthisisgivenbyD[(r??,i ,i ),j?1]+dist[r??,i ]. i1 j23 j1 Similar expressions are obtained when consultant 2 or consultant 3 is responsible for processing rj. Since we do not know a priori which of the consultants is responsible for processing rj in j locations procedure MinimizeTravelCost(dist[1..k][1..k],R[1..n]) Initialize array D[1...k, 1..k, 1..k, 0..n]fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo D[i1, i2, i3, 0] ? dist[1, i1] + dist[1, i2] + dist[1, i3] for j = 1 to n do fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo if R[j]=i1 orR[j]=i2 orR[j]=i3 then D[i1, i2, i3, j] ? D[i1, i2, i3, j ? 1] else D[i1, i2, i3, j] ? min(D[R[j], i2, i3, j dist[R[j], i2], D[i1, i2, R[j], j ? 1] + dist[R[j], i3]) r?∞fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo r ? min(r, D[i1, i2, i3, n]) return r ? 1] + dist[R[j], i1], D[i1, R[j], i3, j ? 1] + Output: maximum total excitement obtainable by a roller coaster consisting of n segments with motion sickness between 0 and 100 at all times. If such a roller coaster is impossible, the output is ?∞. (b) The array is indexed by two indices: i ? {0,1,...,n} and m ? {0,1,2,...,100}. D[i, m] = maximum total excitement of a roller coaster consisting of i segments with motion sickness between 0 and 100 at all times andexactly m at the end of i segments The overall answer is given by max0≤m≤100 D[n, m]. (c) D[0, 0] = 0 D[0,m] = ?∞ for m ? {1,...,100} D[i, m] = max D[i ? 1, m ? M[j]] + E[j] j?[k]:0≤m?M[j]≤100 Where the max returns ?∞ if there is no index j such that 0 ≤ m ? M[j] ≤ 100. 4. (d)  Maximum excitement roller-coaster of length i with motion sickness m at the end (if it can be built) contains some segment of type j as the last segment and a maximum excitement roller- coaster of length i ? 1 with motion sickness m ? M[j] at the end (by cut-and paste property). The last segment then gives excitement E[j] and the excitement accumulated by the first i ? 1 segments is given by D[i ? 1, m ? M[j]]. Since we do not know the value of j a priori, we optimize over all choices of j that are feasible, i.e., maintain motion sickness between 0 and 100. 5. (e)  The array contains O(n) entries, and each entry takes O(k) time to fill in. Thus, the overall running time would be O(nk). 1. (a) COMP 6651: Solutions to Assignment 2 Fall 2022Submission through Moodle is due by October 16th at 23:55 Claim: If f1 > Pni=2 fi then character 1 receives codeword of length 1 in Huffman coding problem. Proof by induction on n:Base case n = 2: in this case both characters receive codewords of length 1, so the claim is trivially true. Inductive assumption: assume that for all inputs with n ≥ 2 characters such that f1 > Pni=2 fi character 1 receives codeword of length 1 in Huffman coding problem. Inductive step: suppose we are given n + 1 characters with frequencies satisfying f1 > Pn+1 fi. i=2 The first step of the Huffman algorithm is that it merges the two characters of lower frequencies together. These two characters cannot be character 1, since we have at least three characters in total (i.e., n+1 ≥ 3) and f1 has highest frequency. Without loss of generality assume that lowest frequency characters are f and f (otherwise, we can reindex the characters). Let f?? denote n n+1 i the new frequencies after the merge operation. That is, we have f?? = f for i ? {1,2,...,n?1} ii and f?? = f + f . Observe that the new frequencies satisfy the inductive assumption, that n n n+1 is, f?? > Pn f??, since Pn f?? = Pn+1 f and f?? = f . Thus, by inductive assumption, the 1i=2i i=2ii=2i11 optimal solution to the new frequencies assigns character 1 codeword of length 1. According to Huffman’s algorithm, the solution to the original problem is obtained from the solution to the new frequencies by expanding the node corresponding to f?? to have two children corresponding n to frequencies fn and fn+1. Clearly, this does not affect the codewords of characters 1,...,n?1. Thus, if character 1 had codeword of length 1 in the solution to the new frequencies, then it also has codeword of length 1 in the solution to the original frequencies. The claim is TRUE. Suppose for contradiction that x is a character with codeword of length 1. Then during the second to last iteration of Huffman’s algorithm, the priority queue must have contents: f?? ≤ f?? ≤ f , abx where a and b are subtrees containing all the other characters (note that if we have f?? ≤ f ≤ f?? axb or f ≤ f?? ≤ f?? then x will be merged into subtree a and won’t get codeword of length 1). Since xab 2. (a) The input is given as an array of reals A[1..n]. First, sort the input points in non-decreasing order. Thus, we have A[1] ≤ A[2] ≤ · · · ≤ A[n] after the sorting operation. Pick the first point A[1] and include the interval [A[1], A[1] + 1] into the solution. Disregard the points covered by this interval, and repeat the procedure by picking the next uncovered point and introducing the unit length interval with that point as the leftmost point of the interval. Continue, until all the points are covered. (b) f < (1/3)Pn f it means that f??,f?? < (1/3)Pn f and f?? +f?? +f < (1/3)Pn f + x j=1j ab j=1j abx j=1j (1/3) Pnj =1 fj + (1/3) Pnj =1 fj = Pnj =1 fj , so the sum of all frequencies of characters is strictly less than Pnj=1 fj, which is a contradiction. (b) procedure CoverPoints(A[1..n]) Sort A in non-decreasing order Initialize solution set of intervals S ? ? i ? 1while i ≤ n do S ? S ? {[A[i], A[i] + 1]}while i + 1 ≤ n and A[i + 1] ≤ A[i] + 1 do i?i+1 i?i+1 return S ? keeps track of the next uncovered point 3. (c) For the following proof suppose that the input array is already sorted A[1] ≤ A[2] ≤ · · · ≤ A[n]. We use the standard greedy loop invariant. Let Si denote the solution obtained by greedy on the first i entries of the array A. (LI): Si can be extended to an optimal solution to the overall instance. Proof by induction on i: Base case i = 0: The solution set S0 is empty and an empty solution can be extended to an optimal solution to the overall instance. Inductive assumption: Assume that for some i ≥ 0 the partial greedy solution Si can be extended to some optimal solution OPT to the overall instance. Inductive step: Consider the partial greedy solution Si+1 on the first i+1 elements. We consider the different cases: Case 1: A[i+1] is covered by one of the intervals in Si. Then Si+1 = Si, by inductive assumption Si can be extended to OPT, therefore so can Si+1. Case 2: A[i + 1] is not covered by one of the intervals in Si. Thus, Si+1 = Si ? {[A[i + 1], A[i + 1]+1]}. Since extension of Si to an optimal solution OPT must cover point A[i+1] and none of the intervals in Si cover A[i+1], there must be some interval I ? OPT such that A[i+1] ? I. If I = [A[i+1],A[i+1]+1] then OPT is also an extension of Si+1 and we are done. If I = [r,r+1] is some other interval covering point A[i + 1], then we can replace it to define a new extension OPT = (OPT \ {I}) ? {[A[i + 1],A[i + 1] + 1]}. We claim that OPT is an optimal extension ]] of S . First observe that |OPT| = |OPT|, thus, the number of intervals in OPT is optimal. i+1 ]] Moreover, we can see that intervals in OPT must cover all the points, since the points A[1..i] ] ] are covered by S and S ? OPT. Moreover, if some point A[j] with j ≥ i + 1 was covered by ii I in OPT then it is covered by [A[i + 1],A[i + 1] + 1] in OPT. Since A[j] being covered by I with j ≥ i+1 implies that A[i+1] < A[j] < r+1 < A[i+1]+1, due to ordering of points and algorithm selecting the rightmost unit-length interval covering A[i + 1]. (d) The sorting operation can be done with MergeSort, for example, in time O(nlogn). The while loop iterates over the array A and does constant amount of work per each entry in A. Thus, the entire amount of work done by the outer while loop is O(n). The overall running time is dominated by the sorting operation and is, therefore, O(n log n). (a) Consider the input with 3 clients located on the line at positions p1 = 1, p2 = 3, p3 = 4. Since clients are located on the line, we have dist[i, j] = |pi ? pj |. Consider the request sequence: p2, p3, p2, p3, p2, p3. The greedy algorithm relocates one of the consultants from p1 to p2 at cost 2 and then this consultant is always the closest for all future requests to p2 and p3 incurring cost 1 for each subsequence request. Thus, the overall cost is 2 + 5 = 7. If, instead, we relocate consultant 1 to process p2 and then consultant 2 to process p3, this initially incurs cost ] (e) (f) 4. (a) the optimal solution, we minimize over the three choices.The optimality of these recursive steps can be seen from the cut-and-paste property. We assume that the requests are given in the array R[1..n] of indices of locations. In the notation above, it means that R[j] = r?? . The dynamic programming table is of size k3n and each entry takes constant time to fill in. Thus, the overall running time is O(k3n). Input: array of integers M[1..k] describing motion sickness of types of segments; array of non-negative integers E[1..k] describing excitement of types of segments; non-negative integer n. (b) 2 + 3 = 5, but all the future requests to p2 and p3 are processed for free. Thus, greedy solution is not optimal. The dynamic programming table is indexed by two indices: first index is a triple (i1, i2, i3) with i1, i2, i3 ? {1, 2, . . . , k} which indicate that consultants are present at locations pi1 , pi2 , pi3 , and the second index is j which indicates the prefix of the request sequence. The semantic array is defined as follows: D[(i1, i2, i3), j] = the cheapest way of processing requests r1, r2, . . . , rj with the three consultants beginning at p1 and ending at locations pi1 , pi2 , pi3 , respectively.The overall answer to the problem is stored in min1≤i1,i2,i3≤k D[(i1, i2, i3), n]. While request r refers to the location of some client, we use notation r?? to refer to the index of jj theclientr,i.e.,ifr =p thenr?? =l. jjlj Base case is when j = 0 then D[(i1, i2, i3), 0] = dist[1, i1] + dist[1, i2] + dist[1, i3] for all i1, i2, i3 ? {1,...,k}.The general case is for j ≥ 1 then we have:If rj is one of the pi1 , pi2 , pi3 then D[(i1, i2, i3), j] = D[(i1, i2, i3), j ? 1]. Otherwise, (c) (d) What is the cheapest way of D[(i ,r??,i ),j?1]+dist[r??,i ], 1j3 j2 D[(i ,i ,r??),j?1]+dist[r??,i ]). 12j j3 processing r1, . . . , rj with consultants ending up atmust travel D[(i ,i ,i ),j]=min(D[(r??,i ,i ),j?1]+dist[r??,i ], 123 j23 j1 pi1 , pi2 , pi3 ? When j = 0 then this is equivalent to saying that the consultants to pi1 , pi2 , pi3 from their initial locations 1, 1, 1. The cost of doing it is dist[1, i1] + dist[1, i2] + dist[1,i3], so this explains the base case. When j > 0 then there are two cases. Case 1: when rj is one of the locations pi1 , pi2 , pi3 . Then we can take the cheapest way of processing requests r1, r2, . . . , rj?1 and consultants ending up in pi1 , pi2 , pi3 and then the request rj is processed for free since we already have a consultant there. Case 2: when rj is not one of the locations pi1 , pi2 , pi3 . Suppose that consultant 1 was responsible for processing rj in the cheapest solution to the subproblem. It means that prior to relocating to pi1 the consultant was at rj to process that request. Thus, the optimal solution consists of processing requests r1, r2, . . . , rj?1 and ending in positions (rj , pi2 , pi3 ), processing request rj , and thenrelocatingconsultant1top . ThecostofthisisgivenbyD[(r??,i ,i ),j?1]+dist[r??,i ]. i1 j23 j1 Similar expressions are obtained when consultant 2 or consultant 3 is responsible for processing rj. Since we do not know a priori which of the consultants is responsible for processing rj in j locations procedure MinimizeTravelCost(dist[1..k][1..k],R[1..n]) Initialize array D[1...k, 1..k, 1..k, 0..n]fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo D[i1, i2, i3, 0] ? dist[1, i1] + dist[1, i2] + dist[1, i3] for j = 1 to n do fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo if R[j]=i1 orR[j]=i2 orR[j]=i3 then D[i1, i2, i3, j] ? D[i1, i2, i3, j ? 1] else D[i1, i2, i3, j] ? min(D[R[j], i2, i3, j dist[R[j], i2], D[i1, i2, R[j], j ? 1] + dist[R[j], i3]) r?∞fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo r ? min(r, D[i1, i2, i3, n]) return r ? 1] + dist[R[j], i1], D[i1, R[j], i3, j ? 1] + Output: maximum total excitement obtainable by a roller coaster consisting of n segments with motion sickness between 0 and 100 at all times. If such a roller coaster is impossible, the output is ?∞. (b) The array is indexed by two indices: i ? {0,1,...,n} and m ? {0,1,2,...,100}. D[i, m] = maximum total excitement of a roller coaster consisting of i segments with motion sickness between 0 and 100 at all times andexactly m at the end of i segments The overall answer is given by max0≤m≤100 D[n, m]. (c) D[0, 0] = 0 D[0,m] = ?∞ for m ? {1,...,100} D[i, m] = max D[i ? 1, m ? M[j]] + E[j] j?[k]:0≤m?M[j]≤100 Where the max returns ?∞ if there is no index j such that 0 ≤ m ? M[j] ≤ 100. 4. (d)  Maximum excitement roller-coaster of length i with motion sickness m at the end (if it can be built) contains some segment of type j as the last segment and a maximum excitement roller- coaster of length i ? 1 with motion sickness m ? M[j] at the end (by cut-and paste property). The last segment then gives excitement E[j] and the excitement accumulated by the first i ? 1 segments is given by D[i ? 1, m ? M[j]]. Since we do not know the value of j a priori, we optimize over all choices of j that are feasible, i.e., maintain motion sickness between 0 and 100. 5. (e)  The array contains O(n) entries, and each entry takes O(k) time to fill in. Thus, the overall running time would be O(nk). 1. (a) COMP 6651: Solutions to Assignment 2 Fall 2022Submission through Moodle is due by October 16th at 23:55 Claim: If f1 > Pni=2 fi then character 1 receives codeword of length 1 in Huffman coding problem. Proof by induction on n:Base case n = 2: in this case both characters receive codewords of length 1, so the claim is trivially true. Inductive assumption: assume that for all inputs with n ≥ 2 characters such that f1 > Pni=2 fi character 1 receives codeword of length 1 in Huffman coding problem. Inductive step: suppose we are given n + 1 characters with frequencies satisfying f1 > Pn+1 fi. i=2 The first step of the Huffman algorithm is that it merges the two characters of lower frequencies together. These two characters cannot be character 1, since we have at least three characters in total (i.e., n+1 ≥ 3) and f1 has highest frequency. Without loss of generality assume that lowest frequency characters are f and f (otherwise, we can reindex the characters). Let f?? denote n n+1 i the new frequencies after the merge operation. That is, we have f?? = f for i ? {1,2,...,n?1} ii and f?? = f + f . Observe that the new frequencies satisfy the inductive assumption, that n n n+1 is, f?? > Pn f??, since Pn f?? = Pn+1 f and f?? = f . Thus, by inductive assumption, the 1i=2i i=2ii=2i11 optimal solution to the new frequencies assigns character 1 codeword of length 1. According to Huffman’s algorithm, the solution to the original problem is obtained from the solution to the new frequencies by expanding the node corresponding to f?? to have two children corresponding n to frequencies fn and fn+1. Clearly, this does not affect the codewords of characters 1,...,n?1. Thus, if character 1 had codeword of length 1 in the solution to the new frequencies, then it also has codeword of length 1 in the solution to the original frequencies. The claim is TRUE. Suppose for contradiction that x is a character with codeword of length 1. Then during the second to last iteration of Huffman’s algorithm, the priority queue must have contents: f?? ≤ f?? ≤ f , abx where a and b are subtrees containing all the other characters (note that if we have f?? ≤ f ≤ f?? axb or f ≤ f?? ≤ f?? then x will be merged into subtree a and won’t get codeword of length 1). Since xab 2. (a) The input is given as an array of reals A[1..n]. First, sort the input points in non-decreasing order. Thus, we have A[1] ≤ A[2] ≤ · · · ≤ A[n] after the sorting operation. Pick the first point A[1] and include the interval [A[1], A[1] + 1] into the solution. Disregard the points covered by this interval, and repeat the procedure by picking the next uncovered point and introducing the unit length interval with that point as the leftmost point of the interval. Continue, until all the points are covered. (b) f < (1/3)Pn f it means that f??,f?? < (1/3)Pn f and f?? +f?? +f < (1/3)Pn f + x j=1j ab j=1j abx j=1j (1/3) Pnj =1 fj + (1/3) Pnj =1 fj = Pnj =1 fj , so the sum of all frequencies of characters is strictly less than Pnj=1 fj, which is a contradiction. (b) procedure CoverPoints(A[1..n]) Sort A in non-decreasing order Initialize solution set of intervals S ? ? i ? 1while i ≤ n do S ? S ? {[A[i], A[i] + 1]}while i + 1 ≤ n and A[i + 1] ≤ A[i] + 1 do i?i+1 i?i+1 return S ? keeps track of the next uncovered point 3. (c) For the following proof suppose that the input array is already sorted A[1] ≤ A[2] ≤ · · · ≤ A[n]. We use the standard greedy loop invariant. Let Si denote the solution obtained by greedy on the first i entries of the array A. (LI): Si can be extended to an optimal solution to the overall instance. Proof by induction on i: Base case i = 0: The solution set S0 is empty and an empty solution can be extended to an optimal solution to the overall instance. Inductive assumption: Assume that for some i ≥ 0 the partial greedy solution Si can be extended to some optimal solution OPT to the overall instance. Inductive step: Consider the partial greedy solution Si+1 on the first i+1 elements. We consider the different cases: Case 1: A[i+1] is covered by one of the intervals in Si. Then Si+1 = Si, by inductive assumption Si can be extended to OPT, therefore so can Si+1. Case 2: A[i + 1] is not covered by one of the intervals in Si. Thus, Si+1 = Si ? {[A[i + 1], A[i + 1]+1]}. Since extension of Si to an optimal solution OPT must cover point A[i+1] and none of the intervals in Si cover A[i+1], there must be some interval I ? OPT such that A[i+1] ? I. If I = [A[i+1],A[i+1]+1] then OPT is also an extension of Si+1 and we are done. If I = [r,r+1] is some other interval covering point A[i + 1], then we can replace it to define a new extension OPT = (OPT \ {I}) ? {[A[i + 1],A[i + 1] + 1]}. We claim that OPT is an optimal extension ]] of S . First observe that |OPT| = |OPT|, thus, the number of intervals in OPT is optimal. i+1 ]] Moreover, we can see that intervals in OPT must cover all the points, since the points A[1..i] ] ] are covered by S and S ? OPT. Moreover, if some point A[j] with j ≥ i + 1 was covered by ii I in OPT then it is covered by [A[i + 1],A[i + 1] + 1] in OPT. Since A[j] being covered by I with j ≥ i+1 implies that A[i+1] < A[j] < r+1 < A[i+1]+1, due to ordering of points and algorithm selecting the rightmost unit-length interval covering A[i + 1]. (d) The sorting operation can be done with MergeSort, for example, in time O(nlogn). The while loop iterates over the array A and does constant amount of work per each entry in A. Thus, the entire amount of work done by the outer while loop is O(n). The overall running time is dominated by the sorting operation and is, therefore, O(n log n). (a) Consider the input with 3 clients located on the line at positions p1 = 1, p2 = 3, p3 = 4. Since clients are located on the line, we have dist[i, j] = |pi ? pj |. Consider the request sequence: p2, p3, p2, p3, p2, p3. The greedy algorithm relocates one of the consultants from p1 to p2 at cost 2 and then this consultant is always the closest for all future requests to p2 and p3 incurring cost 1 for each subsequence request. Thus, the overall cost is 2 + 5 = 7. If, instead, we relocate consultant 1 to process p2 and then consultant 2 to process p3, this initially incurs cost ] (e) (f) 4. (a) the optimal solution, we minimize over the three choices.The optimality of these recursive steps can be seen from the cut-and-paste property. We assume that the requests are given in the array R[1..n] of indices of locations. In the notation above, it means that R[j] = r?? . The dynamic programming table is of size k3n and each entry takes constant time to fill in. Thus, the overall running time is O(k3n). Input: array of integers M[1..k] describing motion sickness of types of segments; array of non-negative integers E[1..k] describing excitement of types of segments; non-negative integer n. (b) 2 + 3 = 5, but all the future requests to p2 and p3 are processed for free. Thus, greedy solution is not optimal. The dynamic programming table is indexed by two indices: first index is a triple (i1, i2, i3) with i1, i2, i3 ? {1, 2, . . . , k} which indicate that consultants are present at locations pi1 , pi2 , pi3 , and the second index is j which indicates the prefix of the request sequence. The semantic array is defined as follows: D[(i1, i2, i3), j] = the cheapest way of processing requests r1, r2, . . . , rj with the three consultants beginning at p1 and ending at locations pi1 , pi2 , pi3 , respectively.The overall answer to the problem is stored in min1≤i1,i2,i3≤k D[(i1, i2, i3), n]. While request r refers to the location of some client, we use notation r?? to refer to the index of jj theclientr,i.e.,ifr =p thenr?? =l. jjlj Base case is when j = 0 then D[(i1, i2, i3), 0] = dist[1, i1] + dist[1, i2] + dist[1, i3] for all i1, i2, i3 ? {1,...,k}.The general case is for j ≥ 1 then we have:If rj is one of the pi1 , pi2 , pi3 then D[(i1, i2, i3), j] = D[(i1, i2, i3), j ? 1]. Otherwise, (c) (d) What is the cheapest way of D[(i ,r??,i ),j?1]+dist[r??,i ], 1j3 j2 D[(i ,i ,r??),j?1]+dist[r??,i ]). 12j j3 processing r1, . . . , rj with consultants ending up atmust travel D[(i ,i ,i ),j]=min(D[(r??,i ,i ),j?1]+dist[r??,i ], 123 j23 j1 pi1 , pi2 , pi3 ? When j = 0 then this is equivalent to saying that the consultants to pi1 , pi2 , pi3 from their initial locations 1, 1, 1. The cost of doing it is dist[1, i1] + dist[1, i2] + dist[1,i3], so this explains the base case. When j > 0 then there are two cases. Case 1: when rj is one of the locations pi1 , pi2 , pi3 . Then we can take the cheapest way of processing requests r1, r2, . . . , rj?1 and consultants ending up in pi1 , pi2 , pi3 and then the request rj is processed for free since we already have a consultant there. Case 2: when rj is not one of the locations pi1 , pi2 , pi3 . Suppose that consultant 1 was responsible for processing rj in the cheapest solution to the subproblem. It means that prior to relocating to pi1 the consultant was at rj to process that request. Thus, the optimal solution consists of processing requests r1, r2, . . . , rj?1 and ending in positions (rj , pi2 , pi3 ), processing request rj , and thenrelocatingconsultant1top . ThecostofthisisgivenbyD[(r??,i ,i ),j?1]+dist[r??,i ]. i1 j23 j1 Similar expressions are obtained when consultant 2 or consultant 3 is responsible for processing rj. Since we do not know a priori which of the consultants is responsible for processing rj in j locations procedure MinimizeTravelCost(dist[1..k][1..k],R[1..n]) Initialize array D[1...k, 1..k, 1..k, 0..n]fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo D[i1, i2, i3, 0] ? dist[1, i1] + dist[1, i2] + dist[1, i3] for j = 1 to n do fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo if R[j]=i1 orR[j]=i2 orR[j]=i3 then D[i1, i2, i3, j] ? D[i1, i2, i3, j ? 1] else D[i1, i2, i3, j] ? min(D[R[j], i2, i3, j dist[R[j], i2], D[i1, i2, R[j], j ? 1] + dist[R[j], i3]) r?∞fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo r ? min(r, D[i1, i2, i3, n]) return r ? 1] + dist[R[j], i1], D[i1, R[j], i3, j ? 1] + Output: maximum total excitement obtainable by a roller coaster consisting of n segments with motion sickness between 0 and 100 at all times. If such a roller coaster is impossible, the output is ?∞. (b) The array is indexed by two indices: i ? {0,1,...,n} and m ? {0,1,2,...,100}. D[i, m] = maximum total excitement of a roller coaster consisting of i segments with motion sickness between 0 and 100 at all times andexactly m at the end of i segments The overall answer is given by max0≤m≤100 D[n, m]. (c) D[0, 0] = 0 D[0,m] = ?∞ for m ? {1,...,100} D[i, m] = max D[i ? 1, m ? M[j]] + E[j] j?[k]:0≤m?M[j]≤100 Where the max returns ?∞ if there is no index j such that 0 ≤ m ? M[j] ≤ 100. 4. (d)  Maximum excitement roller-coaster of length i with motion sickness m at the end (if it can be built) contains some segment of type j as the last segment and a maximum excitement roller- coaster of length i ? 1 with motion sickness m ? M[j] at the end (by cut-and paste property). The last segment then gives excitement E[j] and the excitement accumulated by the first i ? 1 segments is given by D[i ? 1, m ? M[j]]. Since we do not know the value of j a priori, we optimize over all choices of j that are feasible, i.e., maintain motion sickness between 0 and 100. 5. (e)  The array contains O(n) entries, and each entry takes O(k) time to fill in. Thus, the overall running time would be O(nk). 1. (a) COMP 6651: Solutions to Assignment 2 Fall 2022Submission through Moodle is due by October 16th at 23:55 Claim: If f1 > Pni=2 fi then character 1 receives codeword of length 1 in Huffman coding problem. Proof by induction on n:Base case n = 2: in this case both characters receive codewords of length 1, so the claim is trivially true. Inductive assumption: assume that for all inputs with n ≥ 2 characters such that f1 > Pni=2 fi character 1 receives codeword of length 1 in Huffman coding problem. Inductive step: suppose we are given n + 1 characters with frequencies satisfying f1 > Pn+1 fi. i=2 The first step of the Huffman algorithm is that it merges the two characters of lower frequencies together. These two characters cannot be character 1, since we have at least three characters in total (i.e., n+1 ≥ 3) and f1 has highest frequency. Without loss of generality assume that lowest frequency characters are f and f (otherwise, we can reindex the characters). Let f?? denote n n+1 i the new frequencies after the merge operation. That is, we have f?? = f for i ? {1,2,...,n?1} ii and f?? = f + f . Observe that the new frequencies satisfy the inductive assumption, that n n n+1 is, f?? > Pn f??, since Pn f?? = Pn+1 f and f?? = f . Thus, by inductive assumption, the 1i=2i i=2ii=2i11 optimal solution to the new frequencies assigns character 1 codeword of length 1. According to Huffman’s algorithm, the solution to the original problem is obtained from the solution to the new frequencies by expanding the node corresponding to f?? to have two children corresponding n to frequencies fn and fn+1. Clearly, this does not affect the codewords of characters 1,...,n?1. Thus, if character 1 had codeword of length 1 in the solution to the new frequencies, then it also has codeword of length 1 in the solution to the original frequencies. The claim is TRUE. Suppose for contradiction that x is a character with codeword of length 1. Then during the second to last iteration of Huffman’s algorithm, the priority queue must have contents: f?? ≤ f?? ≤ f , abx where a and b are subtrees containing all the other characters (note that if we have f?? ≤ f ≤ f?? axb or f ≤ f?? ≤ f?? then x will be merged into subtree a and won’t get codeword of length 1). Since xab 2. (a) The input is given as an array of reals A[1..n]. First, sort the input points in non-decreasing order. Thus, we have A[1] ≤ A[2] ≤ · · · ≤ A[n] after the sorting operation. Pick the first point A[1] and include the interval [A[1], A[1] + 1] into the solution. Disregard the points covered by this interval, and repeat the procedure by picking the next uncovered point and introducing the unit length interval with that point as the leftmost point of the interval. Continue, until all the points are covered. (b) f < (1/3)Pn f it means that f??,f?? < (1/3)Pn f and f?? +f?? +f < (1/3)Pn f + x j=1j ab j=1j abx j=1j (1/3) Pnj =1 fj + (1/3) Pnj =1 fj = Pnj =1 fj , so the sum of all frequencies of characters is strictly less than Pnj=1 fj, which is a contradiction. (b) procedure CoverPoints(A[1..n]) Sort A in non-decreasing order Initialize solution set of intervals S ? ? i ? 1while i ≤ n do S ? S ? {[A[i], A[i] + 1]}while i + 1 ≤ n and A[i + 1] ≤ A[i] + 1 do i?i+1 i?i+1 return S ? keeps track of the next uncovered point 3. (c) For the following proof suppose that the input array is already sorted A[1] ≤ A[2] ≤ · · · ≤ A[n]. We use the standard greedy loop invariant. Let Si denote the solution obtained by greedy on the first i entries of the array A. (LI): Si can be extended to an optimal solution to the overall instance. Proof by induction on i: Base case i = 0: The solution set S0 is empty and an empty solution can be extended to an optimal solution to the overall instance. Inductive assumption: Assume that for some i ≥ 0 the partial greedy solution Si can be extended to some optimal solution OPT to the overall instance. Inductive step: Consider the partial greedy solution Si+1 on the first i+1 elements. We consider the different cases: Case 1: A[i+1] is covered by one of the intervals in Si. Then Si+1 = Si, by inductive assumption Si can be extended to OPT, therefore so can Si+1. Case 2: A[i + 1] is not covered by one of the intervals in Si. Thus, Si+1 = Si ? {[A[i + 1], A[i + 1]+1]}. Since extension of Si to an optimal solution OPT must cover point A[i+1] and none of the intervals in Si cover A[i+1], there must be some interval I ? OPT such that A[i+1] ? I. If I = [A[i+1],A[i+1]+1] then OPT is also an extension of Si+1 and we are done. If I = [r,r+1] is some other interval covering point A[i + 1], then we can replace it to define a new extension OPT = (OPT \ {I}) ? {[A[i + 1],A[i + 1] + 1]}. We claim that OPT is an optimal extension ]] of S . First observe that |OPT| = |OPT|, thus, the number of intervals in OPT is optimal. i+1 ]] Moreover, we can see that intervals in OPT must cover all the points, since the points A[1..i] ] ] are covered by S and S ? OPT. Moreover, if some point A[j] with j ≥ i + 1 was covered by ii I in OPT then it is covered by [A[i + 1],A[i + 1] + 1] in OPT. Since A[j] being covered by I with j ≥ i+1 implies that A[i+1] < A[j] < r+1 < A[i+1]+1, due to ordering of points and algorithm selecting the rightmost unit-length interval covering A[i + 1]. (d) The sorting operation can be done with MergeSort, for example, in time O(nlogn). The while loop iterates over the array A and does constant amount of work per each entry in A. Thus, the entire amount of work done by the outer while loop is O(n). The overall running time is dominated by the sorting operation and is, therefore, O(n log n). (a) Consider the input with 3 clients located on the line at positions p1 = 1, p2 = 3, p3 = 4. Since clients are located on the line, we have dist[i, j] = |pi ? pj |. Consider the request sequence: p2, p3, p2, p3, p2, p3. The greedy algorithm relocates one of the consultants from p1 to p2 at cost 2 and then this consultant is always the closest for all future requests to p2 and p3 incurring cost 1 for each subsequence request. Thus, the overall cost is 2 + 5 = 7. If, instead, we relocate consultant 1 to process p2 and then consultant 2 to process p3, this initially incurs cost ] (e) (f) 4. (a) the optimal solution, we minimize over the three choices.The optimality of these recursive steps can be seen from the cut-and-paste property. We assume that the requests are given in the array R[1..n] of indices of locations. In the notation above, it means that R[j] = r?? . The dynamic programming table is of size k3n and each entry takes constant time to fill in. Thus, the overall running time is O(k3n). Input: array of integers M[1..k] describing motion sickness of types of segments; array of non-negative integers E[1..k] describing excitement of types of segments; non-negative integer n. (b) 2 + 3 = 5, but all the future requests to p2 and p3 are processed for free. Thus, greedy solution is not optimal. The dynamic programming table is indexed by two indices: first index is a triple (i1, i2, i3) with i1, i2, i3 ? {1, 2, . . . , k} which indicate that consultants are present at locations pi1 , pi2 , pi3 , and the second index is j which indicates the prefix of the request sequence. The semantic array is defined as follows: D[(i1, i2, i3), j] = the cheapest way of processing requests r1, r2, . . . , rj with the three consultants beginning at p1 and ending at locations pi1 , pi2 , pi3 , respectively.The overall answer to the problem is stored in min1≤i1,i2,i3≤k D[(i1, i2, i3), n]. While request r refers to the location of some client, we use notation r?? to refer to the index of jj theclientr,i.e.,ifr =p thenr?? =l. jjlj Base case is when j = 0 then D[(i1, i2, i3), 0] = dist[1, i1] + dist[1, i2] + dist[1, i3] for all i1, i2, i3 ? {1,...,k}.The general case is for j ≥ 1 then we have:If rj is one of the pi1 , pi2 , pi3 then D[(i1, i2, i3), j] = D[(i1, i2, i3), j ? 1]. Otherwise, (c) (d) What is the cheapest way of D[(i ,r??,i ),j?1]+dist[r??,i ], 1j3 j2 D[(i ,i ,r??),j?1]+dist[r??,i ]). 12j j3 processing r1, . . . , rj with consultants ending up atmust travel D[(i ,i ,i ),j]=min(D[(r??,i ,i ),j?1]+dist[r??,i ], 123 j23 j1 pi1 , pi2 , pi3 ? When j = 0 then this is equivalent to saying that the consultants to pi1 , pi2 , pi3 from their initial locations 1, 1, 1. The cost of doing it is dist[1, i1] + dist[1, i2] + dist[1,i3], so this explains the base case. When j > 0 then there are two cases. Case 1: when rj is one of the locations pi1 , pi2 , pi3 . Then we can take the cheapest way of processing requests r1, r2, . . . , rj?1 and consultants ending up in pi1 , pi2 , pi3 and then the request rj is processed for free since we already have a consultant there. Case 2: when rj is not one of the locations pi1 , pi2 , pi3 . Suppose that consultant 1 was responsible for processing rj in the cheapest solution to the subproblem. It means that prior to relocating to pi1 the consultant was at rj to process that request. Thus, the optimal solution consists of processing requests r1, r2, . . . , rj?1 and ending in positions (rj , pi2 , pi3 ), processing request rj , and thenrelocatingconsultant1top . ThecostofthisisgivenbyD[(r??,i ,i ),j?1]+dist[r??,i ]. i1 j23 j1 Similar expressions are obtained when consultant 2 or consultant 3 is responsible for processing rj. Since we do not know a priori which of the consultants is responsible for processing rj in j locations procedure MinimizeTravelCost(dist[1..k][1..k],R[1..n]) Initialize array D[1...k, 1..k, 1..k, 0..n]fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo D[i1, i2, i3, 0] ? dist[1, i1] + dist[1, i2] + dist[1, i3] for j = 1 to n do fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo if R[j]=i1 orR[j]=i2 orR[j]=i3 then D[i1, i2, i3, j] ? D[i1, i2, i3, j ? 1] else D[i1, i2, i3, j] ? min(D[R[j], i2, i3, j dist[R[j], i2], D[i1, i2, R[j], j ? 1] + dist[R[j], i3]) r?∞fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo r ? min(r, D[i1, i2, i3, n]) return r ? 1] + dist[R[j], i1], D[i1, R[j], i3, j ? 1] + Output: maximum total excitement obtainable by a roller coaster consisting of n segments with motion sickness between 0 and 100 at all times. If such a roller coaster is impossible, the output is ?∞. (b) The array is indexed by two indices: i ? {0,1,...,n} and m ? {0,1,2,...,100}. D[i, m] = maximum total excitement of a roller coaster consisting of i segments with motion sickness between 0 and 100 at all times andexactly m at the end of i segments The overall answer is given by max0≤m≤100 D[n, m]. (c) D[0, 0] = 0 D[0,m] = ?∞ for m ? {1,...,100} D[i, m] = max D[i ? 1, m ? M[j]] + E[j] j?[k]:0≤m?M[j]≤100 Where the max returns ?∞ if there is no index j such that 0 ≤ m ? M[j] ≤ 100. 4. (d)  Maximum excitement roller-coaster of length i with motion sickness m at the end (if it can be built) contains some segment of type j as the last segment and a maximum excitement roller- coaster of length i ? 1 with motion sickness m ? M[j] at the end (by cut-and paste property). The last segment then gives excitement E[j] and the excitement accumulated by the first i ? 1 segments is given by D[i ? 1, m ? M[j]]. Since we do not know the value of j a priori, we optimize over all choices of j that are feasible, i.e., maintain motion sickness between 0 and 100. 5. (e)  The array contains O(n) entries, and each entry takes O(k) time to fill in. Thus, the overall running time would be O(nk). 1. (a) COMP 6651: Solutions to Assignment 2 Fall 2022Submission through Moodle is due by October 16th at 23:55 Claim: If f1 > Pni=2 fi then character 1 receives codeword of length 1 in Huffman coding problem. Proof by induction on n:Base case n = 2: in this case both characters receive codewords of length 1, so the claim is trivially true. Inductive assumption: assume that for all inputs with n ≥ 2 characters such that f1 > Pni=2 fi character 1 receives codeword of length 1 in Huffman coding problem. Inductive step: suppose we are given n + 1 characters with frequencies satisfying f1 > Pn+1 fi. i=2 The first step of the Huffman algorithm is that it merges the two characters of lower frequencies together. These two characters cannot be character 1, since we have at least three characters in total (i.e., n+1 ≥ 3) and f1 has highest frequency. Without loss of generality assume that lowest frequency characters are f and f (otherwise, we can reindex the characters). Let f?? denote n n+1 i the new frequencies after the merge operation. That is, we have f?? = f for i ? {1,2,...,n?1} ii and f?? = f + f . Observe that the new frequencies satisfy the inductive assumption, that n n n+1 is, f?? > Pn f??, since Pn f?? = Pn+1 f and f?? = f . Thus, by inductive assumption, the 1i=2i i=2ii=2i11 optimal solution to the new frequencies assigns character 1 codeword of length 1. According to Huffman’s algorithm, the solution to the original problem is obtained from the solution to the new frequencies by expanding the node corresponding to f?? to have two children corresponding n to frequencies fn and fn+1. Clearly, this does not affect the codewords of characters 1,...,n?1. Thus, if character 1 had codeword of length 1 in the solution to the new frequencies, then it also has codeword of length 1 in the solution to the original frequencies. The claim is TRUE. Suppose for contradiction that x is a character with codeword of length 1. Then during the second to last iteration of Huffman’s algorithm, the priority queue must have contents: f?? ≤ f?? ≤ f , abx where a and b are subtrees containing all the other characters (note that if we have f?? ≤ f ≤ f?? axb or f ≤ f?? ≤ f?? then x will be merged into subtree a and won’t get codeword of length 1). Since xab 2. (a) The input is given as an array of reals A[1..n]. First, sort the input points in non-decreasing order. Thus, we have A[1] ≤ A[2] ≤ · · · ≤ A[n] after the sorting operation. Pick the first point A[1] and include the interval [A[1], A[1] + 1] into the solution. Disregard the points covered by this interval, and repeat the procedure by picking the next uncovered point and introducing the unit length interval with that point as the leftmost point of the interval. Continue, until all the points are covered. (b) f < (1/3)Pn f it means that f??,f?? < (1/3)Pn f and f?? +f?? +f < (1/3)Pn f + x j=1j ab j=1j abx j=1j (1/3) Pnj =1 fj + (1/3) Pnj =1 fj = Pnj =1 fj , so the sum of all frequencies of characters is strictly less than Pnj=1 fj, which is a contradiction. (b) procedure CoverPoints(A[1..n]) Sort A in non-decreasing order Initialize solution set of intervals S ? ? i ? 1while i ≤ n do S ? S ? {[A[i], A[i] + 1]}while i + 1 ≤ n and A[i + 1] ≤ A[i] + 1 do i?i+1 i?i+1 return S ? keeps track of the next uncovered point 3. (c) For the following proof suppose that the input array is already sorted A[1] ≤ A[2] ≤ · · · ≤ A[n]. We use the standard greedy loop invariant. Let Si denote the solution obtained by greedy on the first i entries of the array A. (LI): Si can be extended to an optimal solution to the overall instance. Proof by induction on i: Base case i = 0: The solution set S0 is empty and an empty solution can be extended to an optimal solution to the overall instance. Inductive assumption: Assume that for some i ≥ 0 the partial greedy solution Si can be extended to some optimal solution OPT to the overall instance. Inductive step: Consider the partial greedy solution Si+1 on the first i+1 elements. We consider the different cases: Case 1: A[i+1] is covered by one of the intervals in Si. Then Si+1 = Si, by inductive assumption Si can be extended to OPT, therefore so can Si+1. Case 2: A[i + 1] is not covered by one of the intervals in Si. Thus, Si+1 = Si ? {[A[i + 1], A[i + 1]+1]}. Since extension of Si to an optimal solution OPT must cover point A[i+1] and none of the intervals in Si cover A[i+1], there must be some interval I ? OPT such that A[i+1] ? I. If I = [A[i+1],A[i+1]+1] then OPT is also an extension of Si+1 and we are done. If I = [r,r+1] is some other interval covering point A[i + 1], then we can replace it to define a new extension OPT = (OPT \ {I}) ? {[A[i + 1],A[i + 1] + 1]}. We claim that OPT is an optimal extension ]] of S . First observe that |OPT| = |OPT|, thus, the number of intervals in OPT is optimal. i+1 ]] Moreover, we can see that intervals in OPT must cover all the points, since the points A[1..i] ] ] are covered by S and S ? OPT. Moreover, if some point A[j] with j ≥ i + 1 was covered by ii I in OPT then it is covered by [A[i + 1],A[i + 1] + 1] in OPT. Since A[j] being covered by I with j ≥ i+1 implies that A[i+1] < A[j] < r+1 < A[i+1]+1, due to ordering of points and algorithm selecting the rightmost unit-length interval covering A[i + 1]. (d) The sorting operation can be done with MergeSort, for example, in time O(nlogn). The while loop iterates over the array A and does constant amount of work per each entry in A. Thus, the entire amount of work done by the outer while loop is O(n). The overall running time is dominated by the sorting operation and is, therefore, O(n log n). (a) Consider the input with 3 clients located on the line at positions p1 = 1, p2 = 3, p3 = 4. Since clients are located on the line, we have dist[i, j] = |pi ? pj |. Consider the request sequence: p2, p3, p2, p3, p2, p3. The greedy algorithm relocates one of the consultants from p1 to p2 at cost 2 and then this consultant is always the closest for all future requests to p2 and p3 incurring cost 1 for each subsequence request. Thus, the overall cost is 2 + 5 = 7. If, instead, we relocate consultant 1 to process p2 and then consultant 2 to process p3, this initially incurs cost ] (e) (f) 4. (a) the optimal solution, we minimize over the three choices.The optimality of these recursive steps can be seen from the cut-and-paste property. We assume that the requests are given in the array R[1..n] of indices of locations. In the notation above, it means that R[j] = r?? . The dynamic programming table is of size k3n and each entry takes constant time to fill in. Thus, the overall running time is O(k3n). Input: array of integers M[1..k] describing motion sickness of types of segments; array of non-negative integers E[1..k] describing excitement of types of segments; non-negative integer n. (b) 2 + 3 = 5, but all the future requests to p2 and p3 are processed for free. Thus, greedy solution is not optimal. The dynamic programming table is indexed by two indices: first index is a triple (i1, i2, i3) with i1, i2, i3 ? {1, 2, . . . , k} which indicate that consultants are present at locations pi1 , pi2 , pi3 , and the second index is j which indicates the prefix of the request sequence. The semantic array is defined as follows: D[(i1, i2, i3), j] = the cheapest way of processing requests r1, r2, . . . , rj with the three consultants beginning at p1 and ending at locations pi1 , pi2 , pi3 , respectively.The overall answer to the problem is stored in min1≤i1,i2,i3≤k D[(i1, i2, i3), n]. While request r refers to the location of some client, we use notation r?? to refer to the index of jj theclientr,i.e.,ifr =p thenr?? =l. jjlj Base case is when j = 0 then D[(i1, i2, i3), 0] = dist[1, i1] + dist[1, i2] + dist[1, i3] for all i1, i2, i3 ? {1,...,k}.The general case is for j ≥ 1 then we have:If rj is one of the pi1 , pi2 , pi3 then D[(i1, i2, i3), j] = D[(i1, i2, i3), j ? 1]. Otherwise, (c) (d) What is the cheapest way of D[(i ,r??,i ),j?1]+dist[r??,i ], 1j3 j2 D[(i ,i ,r??),j?1]+dist[r??,i ]). 12j j3 processing r1, . . . , rj with consultants ending up atmust travel D[(i ,i ,i ),j]=min(D[(r??,i ,i ),j?1]+dist[r??,i ], 123 j23 j1 pi1 , pi2 , pi3 ? When j = 0 then this is equivalent to saying that the consultants to pi1 , pi2 , pi3 from their initial locations 1, 1, 1. The cost of doing it is dist[1, i1] + dist[1, i2] + dist[1,i3], so this explains the base case. When j > 0 then there are two cases. Case 1: when rj is one of the locations pi1 , pi2 , pi3 . Then we can take the cheapest way of processing requests r1, r2, . . . , rj?1 and consultants ending up in pi1 , pi2 , pi3 and then the request rj is processed for free since we already have a consultant there. Case 2: when rj is not one of the locations pi1 , pi2 , pi3 . Suppose that consultant 1 was responsible for processing rj in the cheapest solution to the subproblem. It means that prior to relocating to pi1 the consultant was at rj to process that request. Thus, the optimal solution consists of processing requests r1, r2, . . . , rj?1 and ending in positions (rj , pi2 , pi3 ), processing request rj , and thenrelocatingconsultant1top . ThecostofthisisgivenbyD[(r??,i ,i ),j?1]+dist[r??,i ]. i1 j23 j1 Similar expressions are obtained when consultant 2 or consultant 3 is responsible for processing rj. Since we do not know a priori which of the consultants is responsible for processing rj in j locations procedure MinimizeTravelCost(dist[1..k][1..k],R[1..n]) Initialize array D[1...k, 1..k, 1..k, 0..n]fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo D[i1, i2, i3, 0] ? dist[1, i1] + dist[1, i2] + dist[1, i3] for j = 1 to n do fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo if R[j]=i1 orR[j]=i2 orR[j]=i3 then D[i1, i2, i3, j] ? D[i1, i2, i3, j ? 1] else D[i1, i2, i3, j] ? min(D[R[j], i2, i3, j dist[R[j], i2], D[i1, i2, R[j], j ? 1] + dist[R[j], i3]) r?∞fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo r ? min(r, D[i1, i2, i3, n]) return r ? 1] + dist[R[j], i1], D[i1, R[j], i3, j ? 1] + Output: maximum total excitement obtainable by a roller coaster consisting of n segments with motion sickness between 0 and 100 at all times. If such a roller coaster is impossible, the output is ?∞. (b) The array is indexed by two indices: i ? {0,1,...,n} and m ? {0,1,2,...,100}. D[i, m] = maximum total excitement of a roller coaster consisting of i segments with motion sickness between 0 and 100 at all times andexactly m at the end of i segments The overall answer is given by max0≤m≤100 D[n, m]. (c) D[0, 0] = 0 D[0,m] = ?∞ for m ? {1,...,100} D[i, m] = max D[i ? 1, m ? M[j]] + E[j] j?[k]:0≤m?M[j]≤100 Where the max returns ?∞ if there is no index j such that 0 ≤ m ? M[j] ≤ 100. 4. (d)  Maximum excitement roller-coaster of length i with motion sickness m at the end (if it can be built) contains some segment of type j as the last segment and a maximum excitement roller- coaster of length i ? 1 with motion sickness m ? M[j] at the end (by cut-and paste property). The last segment then gives excitement E[j] and the excitement accumulated by the first i ? 1 segments is given by D[i ? 1, m ? M[j]]. Since we do not know the value of j a priori, we optimize over all choices of j that are feasible, i.e., maintain motion sickness between 0 and 100. 5. (e)  The array contains O(n) entries, and each entry takes O(k) time to fill in. Thus, the overall running time would be O(nk). 1. (a) COMP 6651: Solutions to Assignment 2 Fall 2022Submission through Moodle is due by October 16th at 23:55 Claim: If f1 > Pni=2 fi then character 1 receives codeword of length 1 in Huffman coding problem. Proof by induction on n:Base case n = 2: in this case both characters receive codewords of length 1, so the claim is trivially true. Inductive assumption: assume that for all inputs with n ≥ 2 characters such that f1 > Pni=2 fi character 1 receives codeword of length 1 in Huffman coding problem. Inductive step: suppose we are given n + 1 characters with frequencies satisfying f1 > Pn+1 fi. i=2 The first step of the Huffman algorithm is that it merges the two characters of lower frequencies together. These two characters cannot be character 1, since we have at least three characters in total (i.e., n+1 ≥ 3) and f1 has highest frequency. Without loss of generality assume that lowest frequency characters are f and f (otherwise, we can reindex the characters). Let f?? denote n n+1 i the new frequencies after the merge operation. That is, we have f?? = f for i ? {1,2,...,n?1} ii and f?? = f + f . Observe that the new frequencies satisfy the inductive assumption, that n n n+1 is, f?? > Pn f??, since Pn f?? = Pn+1 f and f?? = f . Thus, by inductive assumption, the 1i=2i i=2ii=2i11 optimal solution to the new frequencies assigns character 1 codeword of length 1. According to Huffman’s algorithm, the solution to the original problem is obtained from the solution to the new frequencies by expanding the node corresponding to f?? to have two children corresponding n to frequencies fn and fn+1. Clearly, this does not affect the codewords of characters 1,...,n?1. Thus, if character 1 had codeword of length 1 in the solution to the new frequencies, then it also has codeword of length 1 in the solution to the original frequencies. The claim is TRUE. Suppose for contradiction that x is a character with codeword of length 1. Then during the second to last iteration of Huffman’s algorithm, the priority queue must have contents: f?? ≤ f?? ≤ f , abx where a and b are subtrees containing all the other characters (note that if we have f?? ≤ f ≤ f?? axb or f ≤ f?? ≤ f?? then x will be merged into subtree a and won’t get codeword of length 1). Since xab 2. (a) The input is given as an array of reals A[1..n]. First, sort the input points in non-decreasing order. Thus, we have A[1] ≤ A[2] ≤ · · · ≤ A[n] after the sorting operation. Pick the first point A[1] and include the interval [A[1], A[1] + 1] into the solution. Disregard the points covered by this interval, and repeat the procedure by picking the next uncovered point and introducing the unit length interval with that point as the leftmost point of the interval. Continue, until all the points are covered. (b) f < (1/3)Pn f it means that f??,f?? < (1/3)Pn f and f?? +f?? +f < (1/3)Pn f + x j=1j ab j=1j abx j=1j (1/3) Pnj =1 fj + (1/3) Pnj =1 fj = Pnj =1 fj , so the sum of all frequencies of characters is strictly less than Pnj=1 fj, which is a contradiction. (b) procedure CoverPoints(A[1..n]) Sort A in non-decreasing order Initialize solution set of intervals S ? ? i ? 1while i ≤ n do S ? S ? {[A[i], A[i] + 1]}while i + 1 ≤ n and A[i + 1] ≤ A[i] + 1 do i?i+1 i?i+1 return S ? keeps track of the next uncovered point 3. (c) For the following proof suppose that the input array is already sorted A[1] ≤ A[2] ≤ · · · ≤ A[n]. We use the standard greedy loop invariant. Let Si denote the solution obtained by greedy on the first i entries of the array A. (LI): Si can be extended to an optimal solution to the overall instance. Proof by induction on i: Base case i = 0: The solution set S0 is empty and an empty solution can be extended to an optimal solution to the overall instance. Inductive assumption: Assume that for some i ≥ 0 the partial greedy solution Si can be extended to some optimal solution OPT to the overall instance. Inductive step: Consider the partial greedy solution Si+1 on the first i+1 elements. We consider the different cases: Case 1: A[i+1] is covered by one of the intervals in Si. Then Si+1 = Si, by inductive assumption Si can be extended to OPT, therefore so can Si+1. Case 2: A[i + 1] is not covered by one of the intervals in Si. Thus, Si+1 = Si ? {[A[i + 1], A[i + 1]+1]}. Since extension of Si to an optimal solution OPT must cover point A[i+1] and none of the intervals in Si cover A[i+1], there must be some interval I ? OPT such that A[i+1] ? I. If I = [A[i+1],A[i+1]+1] then OPT is also an extension of Si+1 and we are done. If I = [r,r+1] is some other interval covering point A[i + 1], then we can replace it to define a new extension OPT = (OPT \ {I}) ? {[A[i + 1],A[i + 1] + 1]}. We claim that OPT is an optimal extension ]] of S . First observe that |OPT| = |OPT|, thus, the number of intervals in OPT is optimal. i+1 ]] Moreover, we can see that intervals in OPT must cover all the points, since the points A[1..i] ] ] are covered by S and S ? OPT. Moreover, if some point A[j] with j ≥ i + 1 was covered by ii I in OPT then it is covered by [A[i + 1],A[i + 1] + 1] in OPT. Since A[j] being covered by I with j ≥ i+1 implies that A[i+1] < A[j] < r+1 < A[i+1]+1, due to ordering of points and algorithm selecting the rightmost unit-length interval covering A[i + 1]. (d) The sorting operation can be done with MergeSort, for example, in time O(nlogn). The while loop iterates over the array A and does constant amount of work per each entry in A. Thus, the entire amount of work done by the outer while loop is O(n). The overall running time is dominated by the sorting operation and is, therefore, O(n log n). (a) Consider the input with 3 clients located on the line at positions p1 = 1, p2 = 3, p3 = 4. Since clients are located on the line, we have dist[i, j] = |pi ? pj |. Consider the request sequence: p2, p3, p2, p3, p2, p3. The greedy algorithm relocates one of the consultants from p1 to p2 at cost 2 and then this consultant is always the closest for all future requests to p2 and p3 incurring cost 1 for each subsequence request. Thus, the overall cost is 2 + 5 = 7. If, instead, we relocate consultant 1 to process p2 and then consultant 2 to process p3, this initially incurs cost ] (e) (f) 4. (a) the optimal solution, we minimize over the three choices.The optimality of these recursive steps can be seen from the cut-and-paste property. We assume that the requests are given in the array R[1..n] of indices of locations. In the notation above, it means that R[j] = r?? . The dynamic programming table is of size k3n and each entry takes constant time to fill in. Thus, the overall running time is O(k3n). Input: array of integers M[1..k] describing motion sickness of types of segments; array of non-negative integers E[1..k] describing excitement of types of segments; non-negative integer n. (b) 2 + 3 = 5, but all the future requests to p2 and p3 are processed for free. Thus, greedy solution is not optimal. The dynamic programming table is indexed by two indices: first index is a triple (i1, i2, i3) with i1, i2, i3 ? {1, 2, . . . , k} which indicate that consultants are present at locations pi1 , pi2 , pi3 , and the second index is j which indicates the prefix of the request sequence. The semantic array is defined as follows: D[(i1, i2, i3), j] = the cheapest way of processing requests r1, r2, . . . , rj with the three consultants beginning at p1 and ending at locations pi1 , pi2 , pi3 , respectively.The overall answer to the problem is stored in min1≤i1,i2,i3≤k D[(i1, i2, i3), n]. While request r refers to the location of some client, we use notation r?? to refer to the index of jj theclientr,i.e.,ifr =p thenr?? =l. jjlj Base case is when j = 0 then D[(i1, i2, i3), 0] = dist[1, i1] + dist[1, i2] + dist[1, i3] for all i1, i2, i3 ? {1,...,k}.The general case is for j ≥ 1 then we have:If rj is one of the pi1 , pi2 , pi3 then D[(i1, i2, i3), j] = D[(i1, i2, i3), j ? 1]. Otherwise, (c) (d) What is the cheapest way of D[(i ,r??,i ),j?1]+dist[r??,i ], 1j3 j2 D[(i ,i ,r??),j?1]+dist[r??,i ]). 12j j3 processing r1, . . . , rj with consultants ending up atmust travel D[(i ,i ,i ),j]=min(D[(r??,i ,i ),j?1]+dist[r??,i ], 123 j23 j1 pi1 , pi2 , pi3 ? When j = 0 then this is equivalent to saying that the consultants to pi1 , pi2 , pi3 from their initial locations 1, 1, 1. The cost of doing it is dist[1, i1] + dist[1, i2] + dist[1,i3], so this explains the base case. When j > 0 then there are two cases. Case 1: when rj is one of the locations pi1 , pi2 , pi3 . Then we can take the cheapest way of processing requests r1, r2, . . . , rj?1 and consultants ending up in pi1 , pi2 , pi3 and then the request rj is processed for free since we already have a consultant there. Case 2: when rj is not one of the locations pi1 , pi2 , pi3 . Suppose that consultant 1 was responsible for processing rj in the cheapest solution to the subproblem. It means that prior to relocating to pi1 the consultant was at rj to process that request. Thus, the optimal solution consists of processing requests r1, r2, . . . , rj?1 and ending in positions (rj , pi2 , pi3 ), processing request rj , and thenrelocatingconsultant1top . ThecostofthisisgivenbyD[(r??,i ,i ),j?1]+dist[r??,i ]. i1 j23 j1 Similar expressions are obtained when consultant 2 or consultant 3 is responsible for processing rj. Since we do not know a priori which of the consultants is responsible for processing rj in j locations procedure MinimizeTravelCost(dist[1..k][1..k],R[1..n]) Initialize array D[1...k, 1..k, 1..k, 0..n]fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo D[i1, i2, i3, 0] ? dist[1, i1] + dist[1, i2] + dist[1, i3] for j = 1 to n do fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo if R[j]=i1 orR[j]=i2 orR[j]=i3 then D[i1, i2, i3, j] ? D[i1, i2, i3, j ? 1] else D[i1, i2, i3, j] ? min(D[R[j], i2, i3, j dist[R[j], i2], D[i1, i2, R[j], j ? 1] + dist[R[j], i3]) r?∞fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo r ? min(r, D[i1, i2, i3, n]) return r ? 1] + dist[R[j], i1], D[i1, R[j], i3, j ? 1] + Output: maximum total excitement obtainable by a roller coaster consisting of n segments with motion sickness between 0 and 100 at all times. If such a roller coaster is impossible, the output is ?∞. (b) The array is indexed by two indices: i ? {0,1,...,n} and m ? {0,1,2,...,100}. D[i, m] = maximum total excitement of a roller coaster consisting of i segments with motion sickness between 0 and 100 at all times andexactly m at the end of i segments The overall answer is given by max0≤m≤100 D[n, m]. (c) D[0, 0] = 0 D[0,m] = ?∞ for m ? {1,...,100} D[i, m] = max D[i ? 1, m ? M[j]] + E[j] j?[k]:0≤m?M[j]≤100 Where the max returns ?∞ if there is no index j such that 0 ≤ m ? M[j] ≤ 100. 4. (d)  Maximum excitement roller-coaster of length i with motion sickness m at the end (if it can be built) contains some segment of type j as the last segment and a maximum excitement roller- coaster of length i ? 1 with motion sickness m ? M[j] at the end (by cut-and paste property). The last segment then gives excitement E[j] and the excitement accumulated by the first i ? 1 segments is given by D[i ? 1, m ? M[j]]. Since we do not know the value of j a priori, we optimize over all choices of j that are feasible, i.e., maintain motion sickness between 0 and 100. 5. (e)  The array contains O(n) entries, and each entry takes O(k) time to fill in. Thus, the overall running time would be O(nk). 1. (a) COMP 6651: Solutions to Assignment 2 Fall 2022Submission through Moodle is due by October 16th at 23:55 Claim: If f1 > Pni=2 fi then character 1 receives codeword of length 1 in Huffman coding problem. Proof by induction on n:Base case n = 2: in this case both characters receive codewords of length 1, so the claim is trivially true. Inductive assumption: assume that for all inputs with n ≥ 2 characters such that f1 > Pni=2 fi character 1 receives codeword of length 1 in Huffman coding problem. Inductive step: suppose we are given n + 1 characters with frequencies satisfying f1 > Pn+1 fi. i=2 The first step of the Huffman algorithm is that it merges the two characters of lower frequencies together. These two characters cannot be character 1, since we have at least three characters in total (i.e., n+1 ≥ 3) and f1 has highest frequency. Without loss of generality assume that lowest frequency characters are f and f (otherwise, we can reindex the characters). Let f?? denote n n+1 i the new frequencies after the merge operation. That is, we have f?? = f for i ? {1,2,...,n?1} ii and f?? = f + f . Observe that the new frequencies satisfy the inductive assumption, that n n n+1 is, f?? > Pn f??, since Pn f?? = Pn+1 f and f?? = f . Thus, by inductive assumption, the 1i=2i i=2ii=2i11 optimal solution to the new frequencies assigns character 1 codeword of length 1. According to Huffman’s algorithm, the solution to the original problem is obtained from the solution to the new frequencies by expanding the node corresponding to f?? to have two children corresponding n to frequencies fn and fn+1. Clearly, this does not affect the codewords of characters 1,...,n?1. Thus, if character 1 had codeword of length 1 in the solution to the new frequencies, then it also has codeword of length 1 in the solution to the original frequencies. The claim is TRUE. Suppose for contradiction that x is a character with codeword of length 1. Then during the second to last iteration of Huffman’s algorithm, the priority queue must have contents: f?? ≤ f?? ≤ f , abx where a and b are subtrees containing all the other characters (note that if we have f?? ≤ f ≤ f?? axb or f ≤ f?? ≤ f?? then x will be merged into subtree a and won’t get codeword of length 1). Since xab 2. (a) The input is given as an array of reals A[1..n]. First, sort the input points in non-decreasing order. Thus, we have A[1] ≤ A[2] ≤ · · · ≤ A[n] after the sorting operation. Pick the first point A[1] and include the interval [A[1], A[1] + 1] into the solution. Disregard the points covered by this interval, and repeat the procedure by picking the next uncovered point and introducing the unit length interval with that point as the leftmost point of the interval. Continue, until all the points are covered. (b) f < (1/3)Pn f it means that f??,f?? < (1/3)Pn f and f?? +f?? +f < (1/3)Pn f + x j=1j ab j=1j abx j=1j (1/3) Pnj =1 fj + (1/3) Pnj =1 fj = Pnj =1 fj , so the sum of all frequencies of characters is strictly less than Pnj=1 fj, which is a contradiction. (b) procedure CoverPoints(A[1..n]) Sort A in non-decreasing order Initialize solution set of intervals S ? ? i ? 1while i ≤ n do S ? S ? {[A[i], A[i] + 1]}while i + 1 ≤ n and A[i + 1] ≤ A[i] + 1 do i?i+1 i?i+1 return S ? keeps track of the next uncovered point 3. (c) For the following proof suppose that the input array is already sorted A[1] ≤ A[2] ≤ · · · ≤ A[n]. We use the standard greedy loop invariant. Let Si denote the solution obtained by greedy on the first i entries of the array A. (LI): Si can be extended to an optimal solution to the overall instance. Proof by induction on i: Base case i = 0: The solution set S0 is empty and an empty solution can be extended to an optimal solution to the overall instance. Inductive assumption: Assume that for some i ≥ 0 the partial greedy solution Si can be extended to some optimal solution OPT to the overall instance. Inductive step: Consider the partial greedy solution Si+1 on the first i+1 elements. We consider the different cases: Case 1: A[i+1] is covered by one of the intervals in Si. Then Si+1 = Si, by inductive assumption Si can be extended to OPT, therefore so can Si+1. Case 2: A[i + 1] is not covered by one of the intervals in Si. Thus, Si+1 = Si ? {[A[i + 1], A[i + 1]+1]}. Since extension of Si to an optimal solution OPT must cover point A[i+1] and none of the intervals in Si cover A[i+1], there must be some interval I ? OPT such that A[i+1] ? I. If I = [A[i+1],A[i+1]+1] then OPT is also an extension of Si+1 and we are done. If I = [r,r+1] is some other interval covering point A[i + 1], then we can replace it to define a new extension OPT = (OPT \ {I}) ? {[A[i + 1],A[i + 1] + 1]}. We claim that OPT is an optimal extension ]] of S . First observe that |OPT| = |OPT|, thus, the number of intervals in OPT is optimal. i+1 ]] Moreover, we can see that intervals in OPT must cover all the points, since the points A[1..i] ] ] are covered by S and S ? OPT. Moreover, if some point A[j] with j ≥ i + 1 was covered by ii I in OPT then it is covered by [A[i + 1],A[i + 1] + 1] in OPT. Since A[j] being covered by I with j ≥ i+1 implies that A[i+1] < A[j] < r+1 < A[i+1]+1, due to ordering of points and algorithm selecting the rightmost unit-length interval covering A[i + 1]. (d) The sorting operation can be done with MergeSort, for example, in time O(nlogn). The while loop iterates over the array A and does constant amount of work per each entry in A. Thus, the entire amount of work done by the outer while loop is O(n). The overall running time is dominated by the sorting operation and is, therefore, O(n log n). (a) Consider the input with 3 clients located on the line at positions p1 = 1, p2 = 3, p3 = 4. Since clients are located on the line, we have dist[i, j] = |pi ? pj |. Consider the request sequence: p2, p3, p2, p3, p2, p3. The greedy algorithm relocates one of the consultants from p1 to p2 at cost 2 and then this consultant is always the closest for all future requests to p2 and p3 incurring cost 1 for each subsequence request. Thus, the overall cost is 2 + 5 = 7. If, instead, we relocate consultant 1 to process p2 and then consultant 2 to process p3, this initially incurs cost ] (e) (f) 4. (a) the optimal solution, we minimize over the three choices.The optimality of these recursive steps can be seen from the cut-and-paste property. We assume that the requests are given in the array R[1..n] of indices of locations. In the notation above, it means that R[j] = r?? . The dynamic programming table is of size k3n and each entry takes constant time to fill in. Thus, the overall running time is O(k3n). Input: array of integers M[1..k] describing motion sickness of types of segments; array of non-negative integers E[1..k] describing excitement of types of segments; non-negative integer n. (b) 2 + 3 = 5, but all the future requests to p2 and p3 are processed for free. Thus, greedy solution is not optimal. The dynamic programming table is indexed by two indices: first index is a triple (i1, i2, i3) with i1, i2, i3 ? {1, 2, . . . , k} which indicate that consultants are present at locations pi1 , pi2 , pi3 , and the second index is j which indicates the prefix of the request sequence. The semantic array is defined as follows: D[(i1, i2, i3), j] = the cheapest way of processing requests r1, r2, . . . , rj with the three consultants beginning at p1 and ending at locations pi1 , pi2 , pi3 , respectively.The overall answer to the problem is stored in min1≤i1,i2,i3≤k D[(i1, i2, i3), n]. While request r refers to the location of some client, we use notation r?? to refer to the index of jj theclientr,i.e.,ifr =p thenr?? =l. jjlj Base case is when j = 0 then D[(i1, i2, i3), 0] = dist[1, i1] + dist[1, i2] + dist[1, i3] for all i1, i2, i3 ? {1,...,k}.The general case is for j ≥ 1 then we have:If rj is one of the pi1 , pi2 , pi3 then D[(i1, i2, i3), j] = D[(i1, i2, i3), j ? 1]. Otherwise, (c) (d) What is the cheapest way of D[(i ,r??,i ),j?1]+dist[r??,i ], 1j3 j2 D[(i ,i ,r??),j?1]+dist[r??,i ]). 12j j3 processing r1, . . . , rj with consultants ending up atmust travel D[(i ,i ,i ),j]=min(D[(r??,i ,i ),j?1]+dist[r??,i ], 123 j23 j1 pi1 , pi2 , pi3 ? When j = 0 then this is equivalent to saying that the consultants to pi1 , pi2 , pi3 from their initial locations 1, 1, 1. The cost of doing it is dist[1, i1] + dist[1, i2] + dist[1,i3], so this explains the base case. When j > 0 then there are two cases. Case 1: when rj is one of the locations pi1 , pi2 , pi3 . Then we can take the cheapest way of processing requests r1, r2, . . . , rj?1 and consultants ending up in pi1 , pi2 , pi3 and then the request rj is processed for free since we already have a consultant there. Case 2: when rj is not one of the locations pi1 , pi2 , pi3 . Suppose that consultant 1 was responsible for processing rj in the cheapest solution to the subproblem. It means that prior to relocating to pi1 the consultant was at rj to process that request. Thus, the optimal solution consists of processing requests r1, r2, . . . , rj?1 and ending in positions (rj , pi2 , pi3 ), processing request rj , and thenrelocatingconsultant1top . ThecostofthisisgivenbyD[(r??,i ,i ),j?1]+dist[r??,i ]. i1 j23 j1 Similar expressions are obtained when consultant 2 or consultant 3 is responsible for processing rj. Since we do not know a priori which of the consultants is responsible for processing rj in j locations procedure MinimizeTravelCost(dist[1..k][1..k],R[1..n]) Initialize array D[1...k, 1..k, 1..k, 0..n]fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo D[i1, i2, i3, 0] ? dist[1, i1] + dist[1, i2] + dist[1, i3] for j = 1 to n do fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo if R[j]=i1 orR[j]=i2 orR[j]=i3 then D[i1, i2, i3, j] ? D[i1, i2, i3, j ? 1] else D[i1, i2, i3, j] ? min(D[R[j], i2, i3, j dist[R[j], i2], D[i1, i2, R[j], j ? 1] + dist[R[j], i3]) r?∞fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo r ? min(r, D[i1, i2, i3, n]) return r ? 1] + dist[R[j], i1], D[i1, R[j], i3, j ? 1] + Output: maximum total excitement obtainable by a roller coaster consisting of n segments with motion sickness between 0 and 100 at all times. If such a roller coaster is impossible, the output is ?∞. (b) The array is indexed by two indices: i ? {0,1,...,n} and m ? {0,1,2,...,100}. D[i, m] = maximum total excitement of a roller coaster consisting of i segments with motion sickness between 0 and 100 at all times andexactly m at the end of i segments The overall answer is given by max0≤m≤100 D[n, m]. (c) D[0, 0] = 0 D[0,m] = ?∞ for m ? {1,...,100} D[i, m] = max D[i ? 1, m ? M[j]] + E[j] j?[k]:0≤m?M[j]≤100 Where the max returns ?∞ if there is no index j such that 0 ≤ m ? M[j] ≤ 100. 4. (d)  Maximum excitement roller-coaster of length i with motion sickness m at the end (if it can be built) contains some segment of type j as the last segment and a maximum excitement roller- coaster of length i ? 1 with motion sickness m ? M[j] at the end (by cut-and paste property). The last segment then gives excitement E[j] and the excitement accumulated by the first i ? 1 segments is given by D[i ? 1, m ? M[j]]. Since we do not know the value of j a priori, we optimize over all choices of j that are feasible, i.e., maintain motion sickness between 0 and 100. 5. (e)  The array contains O(n) entries, and each entry takes O(k) time to fill in. Thus, the overall running time would be O(nk). 1. (a) COMP 6651: Solutions to Assignment 2 Fall 2022Submission through Moodle is due by October 16th at 23:55 Claim: If f1 > Pni=2 fi then character 1 receives codeword of length 1 in Huffman coding problem. Proof by induction on n:Base case n = 2: in this case both characters receive codewords of length 1, so the claim is trivially true. Inductive assumption: assume that for all inputs with n ≥ 2 characters such that f1 > Pni=2 fi character 1 receives codeword of length 1 in Huffman coding problem. Inductive step: suppose we are given n + 1 characters with frequencies satisfying f1 > Pn+1 fi. i=2 The first step of the Huffman algorithm is that it merges the two characters of lower frequencies together. These two characters cannot be character 1, since we have at least three characters in total (i.e., n+1 ≥ 3) and f1 has highest frequency. Without loss of generality assume that lowest frequency characters are f and f (otherwise, we can reindex the characters). Let f?? denote n n+1 i the new frequencies after the merge operation. That is, we have f?? = f for i ? {1,2,...,n?1} ii and f?? = f + f . Observe that the new frequencies satisfy the inductive assumption, that n n n+1 is, f?? > Pn f??, since Pn f?? = Pn+1 f and f?? = f . Thus, by inductive assumption, the 1i=2i i=2ii=2i11 optimal solution to the new frequencies assigns character 1 codeword of length 1. According to Huffman’s algorithm, the solution to the original problem is obtained from the solution to the new frequencies by expanding the node corresponding to f?? to have two children corresponding n to frequencies fn and fn+1. Clearly, this does not affect the codewords of characters 1,...,n?1. Thus, if character 1 had codeword of length 1 in the solution to the new frequencies, then it also has codeword of length 1 in the solution to the original frequencies. The claim is TRUE. Suppose for contradiction that x is a character with codeword of length 1. Then during the second to last iteration of Huffman’s algorithm, the priority queue must have contents: f?? ≤ f?? ≤ f , abx where a and b are subtrees containing all the other characters (note that if we have f?? ≤ f ≤ f?? axb or f ≤ f?? ≤ f?? then x will be merged into subtree a and won’t get codeword of length 1). Since xab 2. (a) The input is given as an array of reals A[1..n]. First, sort the input points in non-decreasing order. Thus, we have A[1] ≤ A[2] ≤ · · · ≤ A[n] after the sorting operation. Pick the first point A[1] and include the interval [A[1], A[1] + 1] into the solution. Disregard the points covered by this interval, and repeat the procedure by picking the next uncovered point and introducing the unit length interval with that point as the leftmost point of the interval. Continue, until all the points are covered. (b) f < (1/3)Pn f it means that f??,f?? < (1/3)Pn f and f?? +f?? +f < (1/3)Pn f + x j=1j ab j=1j abx j=1j (1/3) Pnj =1 fj + (1/3) Pnj =1 fj = Pnj =1 fj , so the sum of all frequencies of characters is strictly less than Pnj=1 fj, which is a contradiction. (b) procedure CoverPoints(A[1..n]) Sort A in non-decreasing order Initialize solution set of intervals S ? ? i ? 1while i ≤ n do S ? S ? {[A[i], A[i] + 1]}while i + 1 ≤ n and A[i + 1] ≤ A[i] + 1 do i?i+1 i?i+1 return S ? keeps track of the next uncovered point 3. (c) For the following proof suppose that the input array is already sorted A[1] ≤ A[2] ≤ · · · ≤ A[n]. We use the standard greedy loop invariant. Let Si denote the solution obtained by greedy on the first i entries of the array A. (LI): Si can be extended to an optimal solution to the overall instance. Proof by induction on i: Base case i = 0: The solution set S0 is empty and an empty solution can be extended to an optimal solution to the overall instance. Inductive assumption: Assume that for some i ≥ 0 the partial greedy solution Si can be extended to some optimal solution OPT to the overall instance. Inductive step: Consider the partial greedy solution Si+1 on the first i+1 elements. We consider the different cases: Case 1: A[i+1] is covered by one of the intervals in Si. Then Si+1 = Si, by inductive assumption Si can be extended to OPT, therefore so can Si+1. Case 2: A[i + 1] is not covered by one of the intervals in Si. Thus, Si+1 = Si ? {[A[i + 1], A[i + 1]+1]}. Since extension of Si to an optimal solution OPT must cover point A[i+1] and none of the intervals in Si cover A[i+1], there must be some interval I ? OPT such that A[i+1] ? I. If I = [A[i+1],A[i+1]+1] then OPT is also an extension of Si+1 and we are done. If I = [r,r+1] is some other interval covering point A[i + 1], then we can replace it to define a new extension OPT = (OPT \ {I}) ? {[A[i + 1],A[i + 1] + 1]}. We claim that OPT is an optimal extension ]] of S . First observe that |OPT| = |OPT|, thus, the number of intervals in OPT is optimal. i+1 ]] Moreover, we can see that intervals in OPT must cover all the points, since the points A[1..i] ] ] are covered by S and S ? OPT. Moreover, if some point A[j] with j ≥ i + 1 was covered by ii I in OPT then it is covered by [A[i + 1],A[i + 1] + 1] in OPT. Since A[j] being covered by I with j ≥ i+1 implies that A[i+1] < A[j] < r+1 < A[i+1]+1, due to ordering of points and algorithm selecting the rightmost unit-length interval covering A[i + 1]. (d) The sorting operation can be done with MergeSort, for example, in time O(nlogn). The while loop iterates over the array A and does constant amount of work per each entry in A. Thus, the entire amount of work done by the outer while loop is O(n). The overall running time is dominated by the sorting operation and is, therefore, O(n log n). (a) Consider the input with 3 clients located on the line at positions p1 = 1, p2 = 3, p3 = 4. Since clients are located on the line, we have dist[i, j] = |pi ? pj |. Consider the request sequence: p2, p3, p2, p3, p2, p3. The greedy algorithm relocates one of the consultants from p1 to p2 at cost 2 and then this consultant is always the closest for all future requests to p2 and p3 incurring cost 1 for each subsequence request. Thus, the overall cost is 2 + 5 = 7. If, instead, we relocate consultant 1 to process p2 and then consultant 2 to process p3, this initially incurs cost ] (e) (f) 4. (a) the optimal solution, we minimize over the three choices.The optimality of these recursive steps can be seen from the cut-and-paste property. We assume that the requests are given in the array R[1..n] of indices of locations. In the notation above, it means that R[j] = r?? . The dynamic programming table is of size k3n and each entry takes constant time to fill in. Thus, the overall running time is O(k3n). Input: array of integers M[1..k] describing motion sickness of types of segments; array of non-negative integers E[1..k] describing excitement of types of segments; non-negative integer n. (b) 2 + 3 = 5, but all the future requests to p2 and p3 are processed for free. Thus, greedy solution is not optimal. The dynamic programming table is indexed by two indices: first index is a triple (i1, i2, i3) with i1, i2, i3 ? {1, 2, . . . , k} which indicate that consultants are present at locations pi1 , pi2 , pi3 , and the second index is j which indicates the prefix of the request sequence. The semantic array is defined as follows: D[(i1, i2, i3), j] = the cheapest way of processing requests r1, r2, . . . , rj with the three consultants beginning at p1 and ending at locations pi1 , pi2 , pi3 , respectively.The overall answer to the problem is stored in min1≤i1,i2,i3≤k D[(i1, i2, i3), n]. While request r refers to the location of some client, we use notation r?? to refer to the index of jj theclientr,i.e.,ifr =p thenr?? =l. jjlj Base case is when j = 0 then D[(i1, i2, i3), 0] = dist[1, i1] + dist[1, i2] + dist[1, i3] for all i1, i2, i3 ? {1,...,k}.The general case is for j ≥ 1 then we have:If rj is one of the pi1 , pi2 , pi3 then D[(i1, i2, i3), j] = D[(i1, i2, i3), j ? 1]. Otherwise, (c) (d) What is the cheapest way of D[(i ,r??,i ),j?1]+dist[r??,i ], 1j3 j2 D[(i ,i ,r??),j?1]+dist[r??,i ]). 12j j3 processing r1, . . . , rj with consultants ending up atmust travel D[(i ,i ,i ),j]=min(D[(r??,i ,i ),j?1]+dist[r??,i ], 123 j23 j1 pi1 , pi2 , pi3 ? When j = 0 then this is equivalent to saying that the consultants to pi1 , pi2 , pi3 from their initial locations 1, 1, 1. The cost of doing it is dist[1, i1] + dist[1, i2] + dist[1,i3], so this explains the base case. When j > 0 then there are two cases. Case 1: when rj is one of the locations pi1 , pi2 , pi3 . Then we can take the cheapest way of processing requests r1, r2, . . . , rj?1 and consultants ending up in pi1 , pi2 , pi3 and then the request rj is processed for free since we already have a consultant there. Case 2: when rj is not one of the locations pi1 , pi2 , pi3 . Suppose that consultant 1 was responsible for processing rj in the cheapest solution to the subproblem. It means that prior to relocating to pi1 the consultant was at rj to process that request. Thus, the optimal solution consists of processing requests r1, r2, . . . , rj?1 and ending in positions (rj , pi2 , pi3 ), processing request rj , and thenrelocatingconsultant1top . ThecostofthisisgivenbyD[(r??,i ,i ),j?1]+dist[r??,i ]. i1 j23 j1 Similar expressions are obtained when consultant 2 or consultant 3 is responsible for processing rj. Since we do not know a priori which of the consultants is responsible for processing rj in j locations procedure MinimizeTravelCost(dist[1..k][1..k],R[1..n]) Initialize array D[1...k, 1..k, 1..k, 0..n]fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo D[i1, i2, i3, 0] ? dist[1, i1] + dist[1, i2] + dist[1, i3] for j = 1 to n do fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo if R[j]=i1 orR[j]=i2 orR[j]=i3 then D[i1, i2, i3, j] ? D[i1, i2, i3, j ? 1] else D[i1, i2, i3, j] ? min(D[R[j], i2, i3, j dist[R[j], i2], D[i1, i2, R[j], j ? 1] + dist[R[j], i3]) r?∞fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo r ? min(r, D[i1, i2, i3, n]) return r ? 1] + dist[R[j], i1], D[i1, R[j], i3, j ? 1] + Output: maximum total excitement obtainable by a roller coaster consisting of n segments with motion sickness between 0 and 100 at all times. If such a roller coaster is impossible, the output is ?∞. (b) The array is indexed by two indices: i ? {0,1,...,n} and m ? {0,1,2,...,100}. D[i, m] = maximum total excitement of a roller coaster consisting of i segments with motion sickness between 0 and 100 at all times andexactly m at the end of i segments The overall answer is given by max0≤m≤100 D[n, m]. (c) D[0, 0] = 0 D[0,m] = ?∞ for m ? {1,...,100} D[i, m] = max D[i ? 1, m ? M[j]] + E[j] j?[k]:0≤m?M[j]≤100 Where the max returns ?∞ if there is no index j such that 0 ≤ m ? M[j] ≤ 100. 4. (d)  Maximum excitement roller-coaster of length i with motion sickness m at the end (if it can be built) contains some segment of type j as the last segment and a maximum excitement roller- coaster of length i ? 1 with motion sickness m ? M[j] at the end (by cut-and paste property). The last segment then gives excitement E[j] and the excitement accumulated by the first i ? 1 segments is given by D[i ? 1, m ? M[j]]. Since we do not know the value of j a priori, we optimize over all choices of j that are feasible, i.e., maintain motion sickness between 0 and 100. 5. (e)  The array contains O(n) entries, and each entry takes O(k) time to fill in. Thus, the overall running time would be O(nk). 1. (a) COMP 6651: Solutions to Assignment 2 Fall 2022Submission through Moodle is due by October 16th at 23:55 Claim: If f1 > Pni=2 fi then character 1 receives codeword of length 1 in Huffman coding problem. Proof by induction on n:Base case n = 2: in this case both characters receive codewords of length 1, so the claim is trivially true. Inductive assumption: assume that for all inputs with n ≥ 2 characters such that f1 > Pni=2 fi character 1 receives codeword of length 1 in Huffman coding problem. Inductive step: suppose we are given n + 1 characters with frequencies satisfying f1 > Pn+1 fi. i=2 The first step of the Huffman algorithm is that it merges the two characters of lower frequencies together. These two characters cannot be character 1, since we have at least three characters in total (i.e., n+1 ≥ 3) and f1 has highest frequency. Without loss of generality assume that lowest frequency characters are f and f (otherwise, we can reindex the characters). Let f?? denote n n+1 i the new frequencies after the merge operation. That is, we have f?? = f for i ? {1,2,...,n?1} ii and f?? = f + f . Observe that the new frequencies satisfy the inductive assumption, that n n n+1 is, f?? > Pn f??, since Pn f?? = Pn+1 f and f?? = f . Thus, by inductive assumption, the 1i=2i i=2ii=2i11 optimal solution to the new frequencies assigns character 1 codeword of length 1. According to Huffman’s algorithm, the solution to the original problem is obtained from the solution to the new frequencies by expanding the node corresponding to f?? to have two children corresponding n to frequencies fn and fn+1. Clearly, this does not affect the codewords of characters 1,...,n?1. Thus, if character 1 had codeword of length 1 in the solution to the new frequencies, then it also has codeword of length 1 in the solution to the original frequencies. The claim is TRUE. Suppose for contradiction that x is a character with codeword of length 1. Then during the second to last iteration of Huffman’s algorithm, the priority queue must have contents: f?? ≤ f?? ≤ f , abx where a and b are subtrees containing all the other characters (note that if we have f?? ≤ f ≤ f?? axb or f ≤ f?? ≤ f?? then x will be merged into subtree a and won’t get codeword of length 1). Since xab 2. (a) The input is given as an array of reals A[1..n]. First, sort the input points in non-decreasing order. Thus, we have A[1] ≤ A[2] ≤ · · · ≤ A[n] after the sorting operation. Pick the first point A[1] and include the interval [A[1], A[1] + 1] into the solution. Disregard the points covered by this interval, and repeat the procedure by picking the next uncovered point and introducing the unit length interval with that point as the leftmost point of the interval. Continue, until all the points are covered. (b) f < (1/3)Pn f it means that f??,f?? < (1/3)Pn f and f?? +f?? +f < (1/3)Pn f + x j=1j ab j=1j abx j=1j (1/3) Pnj =1 fj + (1/3) Pnj =1 fj = Pnj =1 fj , so the sum of all frequencies of characters is strictly less than Pnj=1 fj, which is a contradiction. (b) procedure CoverPoints(A[1..n]) Sort A in non-decreasing order Initialize solution set of intervals S ? ? i ? 1while i ≤ n do S ? S ? {[A[i], A[i] + 1]}while i + 1 ≤ n and A[i + 1] ≤ A[i] + 1 do i?i+1 i?i+1 return S ? keeps track of the next uncovered point 3. (c) For the following proof suppose that the input array is already sorted A[1] ≤ A[2] ≤ · · · ≤ A[n]. We use the standard greedy loop invariant. Let Si denote the solution obtained by greedy on the first i entries of the array A. (LI): Si can be extended to an optimal solution to the overall instance. Proof by induction on i: Base case i = 0: The solution set S0 is empty and an empty solution can be extended to an optimal solution to the overall instance. Inductive assumption: Assume that for some i ≥ 0 the partial greedy solution Si can be extended to some optimal solution OPT to the overall instance. Inductive step: Consider the partial greedy solution Si+1 on the first i+1 elements. We consider the different cases: Case 1: A[i+1] is covered by one of the intervals in Si. Then Si+1 = Si, by inductive assumption Si can be extended to OPT, therefore so can Si+1. Case 2: A[i + 1] is not covered by one of the intervals in Si. Thus, Si+1 = Si ? {[A[i + 1], A[i + 1]+1]}. Since extension of Si to an optimal solution OPT must cover point A[i+1] and none of the intervals in Si cover A[i+1], there must be some interval I ? OPT such that A[i+1] ? I. If I = [A[i+1],A[i+1]+1] then OPT is also an extension of Si+1 and we are done. If I = [r,r+1] is some other interval covering point A[i + 1], then we can replace it to define a new extension OPT = (OPT \ {I}) ? {[A[i + 1],A[i + 1] + 1]}. We claim that OPT is an optimal extension ]] of S . First observe that |OPT| = |OPT|, thus, the number of intervals in OPT is optimal. i+1 ]] Moreover, we can see that intervals in OPT must cover all the points, since the points A[1..i] ] ] are covered by S and S ? OPT. Moreover, if some point A[j] with j ≥ i + 1 was covered by ii I in OPT then it is covered by [A[i + 1],A[i + 1] + 1] in OPT. Since A[j] being covered by I with j ≥ i+1 implies that A[i+1] < A[j] < r+1 < A[i+1]+1, due to ordering of points and algorithm selecting the rightmost unit-length interval covering A[i + 1]. (d) The sorting operation can be done with MergeSort, for example, in time O(nlogn). The while loop iterates over the array A and does constant amount of work per each entry in A. Thus, the entire amount of work done by the outer while loop is O(n). The overall running time is dominated by the sorting operation and is, therefore, O(n log n). (a) Consider the input with 3 clients located on the line at positions p1 = 1, p2 = 3, p3 = 4. Since clients are located on the line, we have dist[i, j] = |pi ? pj |. Consider the request sequence: p2, p3, p2, p3, p2, p3. The greedy algorithm relocates one of the consultants from p1 to p2 at cost 2 and then this consultant is always the closest for all future requests to p2 and p3 incurring cost 1 for each subsequence request. Thus, the overall cost is 2 + 5 = 7. If, instead, we relocate consultant 1 to process p2 and then consultant 2 to process p3, this initially incurs cost ] (e) (f) 4. (a) the optimal solution, we minimize over the three choices.The optimality of these recursive steps can be seen from the cut-and-paste property. We assume that the requests are given in the array R[1..n] of indices of locations. In the notation above, it means that R[j] = r?? . The dynamic programming table is of size k3n and each entry takes constant time to fill in. Thus, the overall running time is O(k3n). Input: array of integers M[1..k] describing motion sickness of types of segments; array of non-negative integers E[1..k] describing excitement of types of segments; non-negative integer n. (b) 2 + 3 = 5, but all the future requests to p2 and p3 are processed for free. Thus, greedy solution is not optimal. The dynamic programming table is indexed by two indices: first index is a triple (i1, i2, i3) with i1, i2, i3 ? {1, 2, . . . , k} which indicate that consultants are present at locations pi1 , pi2 , pi3 , and the second index is j which indicates the prefix of the request sequence. The semantic array is defined as follows: D[(i1, i2, i3), j] = the cheapest way of processing requests r1, r2, . . . , rj with the three consultants beginning at p1 and ending at locations pi1 , pi2 , pi3 , respectively.The overall answer to the problem is stored in min1≤i1,i2,i3≤k D[(i1, i2, i3), n]. While request r refers to the location of some client, we use notation r?? to refer to the index of jj theclientr,i.e.,ifr =p thenr?? =l. jjlj Base case is when j = 0 then D[(i1, i2, i3), 0] = dist[1, i1] + dist[1, i2] + dist[1, i3] for all i1, i2, i3 ? {1,...,k}.The general case is for j ≥ 1 then we have:If rj is one of the pi1 , pi2 , pi3 then D[(i1, i2, i3), j] = D[(i1, i2, i3), j ? 1]. Otherwise, (c) (d) What is the cheapest way of D[(i ,r??,i ),j?1]+dist[r??,i ], 1j3 j2 D[(i ,i ,r??),j?1]+dist[r??,i ]). 12j j3 processing r1, . . . , rj with consultants ending up atmust travel D[(i ,i ,i ),j]=min(D[(r??,i ,i ),j?1]+dist[r??,i ], 123 j23 j1 pi1 , pi2 , pi3 ? When j = 0 then this is equivalent to saying that the consultants to pi1 , pi2 , pi3 from their initial locations 1, 1, 1. The cost of doing it is dist[1, i1] + dist[1, i2] + dist[1,i3], so this explains the base case. When j > 0 then there are two cases. Case 1: when rj is one of the locations pi1 , pi2 , pi3 . Then we can take the cheapest way of processing requests r1, r2, . . . , rj?1 and consultants ending up in pi1 , pi2 , pi3 and then the request rj is processed for free since we already have a consultant there. Case 2: when rj is not one of the locations pi1 , pi2 , pi3 . Suppose that consultant 1 was responsible for processing rj in the cheapest solution to the subproblem. It means that prior to relocating to pi1 the consultant was at rj to process that request. Thus, the optimal solution consists of processing requests r1, r2, . . . , rj?1 and ending in positions (rj , pi2 , pi3 ), processing request rj , and thenrelocatingconsultant1top . ThecostofthisisgivenbyD[(r??,i ,i ),j?1]+dist[r??,i ]. i1 j23 j1 Similar expressions are obtained when consultant 2 or consultant 3 is responsible for processing rj. Since we do not know a priori which of the consultants is responsible for processing rj in j locations procedure MinimizeTravelCost(dist[1..k][1..k],R[1..n]) Initialize array D[1...k, 1..k, 1..k, 0..n]fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo D[i1, i2, i3, 0] ? dist[1, i1] + dist[1, i2] + dist[1, i3] for j = 1 to n do fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo if R[j]=i1 orR[j]=i2 orR[j]=i3 then D[i1, i2, i3, j] ? D[i1, i2, i3, j ? 1] else D[i1, i2, i3, j] ? min(D[R[j], i2, i3, j dist[R[j], i2], D[i1, i2, R[j], j ? 1] + dist[R[j], i3]) r?∞fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo r ? min(r, D[i1, i2, i3, n]) return r ? 1] + dist[R[j], i1], D[i1, R[j], i3, j ? 1] + Output: maximum total excitement obtainable by a roller coaster consisting of n segments with motion sickness between 0 and 100 at all times. If such a roller coaster is impossible, the output is ?∞. (b) The array is indexed by two indices: i ? {0,1,...,n} and m ? {0,1,2,...,100}. D[i, m] = maximum total excitement of a roller coaster consisting of i segments with motion sickness between 0 and 100 at all times andexactly m at the end of i segments The overall answer is given by max0≤m≤100 D[n, m]. (c) D[0, 0] = 0 D[0,m] = ?∞ for m ? {1,...,100} D[i, m] = max D[i ? 1, m ? M[j]] + E[j] j?[k]:0≤m?M[j]≤100 Where the max returns ?∞ if there is no index j such that 0 ≤ m ? M[j] ≤ 100. 4. (d)  Maximum excitement roller-coaster of length i with motion sickness m at the end (if it can be built) contains some segment of type j as the last segment and a maximum excitement roller- coaster of length i ? 1 with motion sickness m ? M[j] at the end (by cut-and paste property). The last segment then gives excitement E[j] and the excitement accumulated by the first i ? 1 segments is given by D[i ? 1, m ? M[j]]. Since we do not know the value of j a priori, we optimize over all choices of j that are feasible, i.e., maintain motion sickness between 0 and 100. 5. (e)  The array contains O(n) entries, and each entry takes O(k) time to fill in. Thus, the overall running time would be O(nk). 1. (a) COMP 6651: Solutions to Assignment 2 Fall 2022Submission through Moodle is due by October 16th at 23:55 Claim: If f1 > Pni=2 fi then character 1 receives codeword of length 1 in Huffman coding problem. Proof by induction on n:Base case n = 2: in this case both characters receive codewords of length 1, so the claim is trivially true. Inductive assumption: assume that for all inputs with n ≥ 2 characters such that f1 > Pni=2 fi character 1 receives codeword of length 1 in Huffman coding problem. Inductive step: suppose we are given n + 1 characters with frequencies satisfying f1 > Pn+1 fi. i=2 The first step of the Huffman algorithm is that it merges the two characters of lower frequencies together. These two characters cannot be character 1, since we have at least three characters in total (i.e., n+1 ≥ 3) and f1 has highest frequency. Without loss of generality assume that lowest frequency characters are f and f (otherwise, we can reindex the characters). Let f?? denote n n+1 i the new frequencies after the merge operation. That is, we have f?? = f for i ? {1,2,...,n?1} ii and f?? = f + f . Observe that the new frequencies satisfy the inductive assumption, that n n n+1 is, f?? > Pn f??, since Pn f?? = Pn+1 f and f?? = f . Thus, by inductive assumption, the 1i=2i i=2ii=2i11 optimal solution to the new frequencies assigns character 1 codeword of length 1. According to Huffman’s algorithm, the solution to the original problem is obtained from the solution to the new frequencies by expanding the node corresponding to f?? to have two children corresponding n to frequencies fn and fn+1. Clearly, this does not affect the codewords of characters 1,...,n?1. Thus, if character 1 had codeword of length 1 in the solution to the new frequencies, then it also has codeword of length 1 in the solution to the original frequencies. The claim is TRUE. Suppose for contradiction that x is a character with codeword of length 1. Then during the second to last iteration of Huffman’s algorithm, the priority queue must have contents: f?? ≤ f?? ≤ f , abx where a and b are subtrees containing all the other characters (note that if we have f?? ≤ f ≤ f?? axb or f ≤ f?? ≤ f?? then x will be merged into subtree a and won’t get codeword of length 1). Since xab 2. (a) The input is given as an array of reals A[1..n]. First, sort the input points in non-decreasing order. Thus, we have A[1] ≤ A[2] ≤ · · · ≤ A[n] after the sorting operation. Pick the first point A[1] and include the interval [A[1], A[1] + 1] into the solution. Disregard the points covered by this interval, and repeat the procedure by picking the next uncovered point and introducing the unit length interval with that point as the leftmost point of the interval. Continue, until all the points are covered. (b) f < (1/3)Pn f it means that f??,f?? < (1/3)Pn f and f?? +f?? +f < (1/3)Pn f + x j=1j ab j=1j abx j=1j (1/3) Pnj =1 fj + (1/3) Pnj =1 fj = Pnj =1 fj , so the sum of all frequencies of characters is strictly less than Pnj=1 fj, which is a contradiction. (b) procedure CoverPoints(A[1..n]) Sort A in non-decreasing order Initialize solution set of intervals S ? ? i ? 1while i ≤ n do S ? S ? {[A[i], A[i] + 1]}while i + 1 ≤ n and A[i + 1] ≤ A[i] + 1 do i?i+1 i?i+1 return S ? keeps track of the next uncovered point 3. (c) For the following proof suppose that the input array is already sorted A[1] ≤ A[2] ≤ · · · ≤ A[n]. We use the standard greedy loop invariant. Let Si denote the solution obtained by greedy on the first i entries of the array A. (LI): Si can be extended to an optimal solution to the overall instance. Proof by induction on i: Base case i = 0: The solution set S0 is empty and an empty solution can be extended to an optimal solution to the overall instance. Inductive assumption: Assume that for some i ≥ 0 the partial greedy solution Si can be extended to some optimal solution OPT to the overall instance. Inductive step: Consider the partial greedy solution Si+1 on the first i+1 elements. We consider the different cases: Case 1: A[i+1] is covered by one of the intervals in Si. Then Si+1 = Si, by inductive assumption Si can be extended to OPT, therefore so can Si+1. Case 2: A[i + 1] is not covered by one of the intervals in Si. Thus, Si+1 = Si ? {[A[i + 1], A[i + 1]+1]}. Since extension of Si to an optimal solution OPT must cover point A[i+1] and none of the intervals in Si cover A[i+1], there must be some interval I ? OPT such that A[i+1] ? I. If I = [A[i+1],A[i+1]+1] then OPT is also an extension of Si+1 and we are done. If I = [r,r+1] is some other interval covering point A[i + 1], then we can replace it to define a new extension OPT = (OPT \ {I}) ? {[A[i + 1],A[i + 1] + 1]}. We claim that OPT is an optimal extension ]] of S . First observe that |OPT| = |OPT|, thus, the number of intervals in OPT is optimal. i+1 ]] Moreover, we can see that intervals in OPT must cover all the points, since the points A[1..i] ] ] are covered by S and S ? OPT. Moreover, if some point A[j] with j ≥ i + 1 was covered by ii I in OPT then it is covered by [A[i + 1],A[i + 1] + 1] in OPT. Since A[j] being covered by I with j ≥ i+1 implies that A[i+1] < A[j] < r+1 < A[i+1]+1, due to ordering of points and algorithm selecting the rightmost unit-length interval covering A[i + 1]. (d) The sorting operation can be done with MergeSort, for example, in time O(nlogn). The while loop iterates over the array A and does constant amount of work per each entry in A. Thus, the entire amount of work done by the outer while loop is O(n). The overall running time is dominated by the sorting operation and is, therefore, O(n log n). (a) Consider the input with 3 clients located on the line at positions p1 = 1, p2 = 3, p3 = 4. Since clients are located on the line, we have dist[i, j] = |pi ? pj |. Consider the request sequence: p2, p3, p2, p3, p2, p3. The greedy algorithm relocates one of the consultants from p1 to p2 at cost 2 and then this consultant is always the closest for all future requests to p2 and p3 incurring cost 1 for each subsequence request. Thus, the overall cost is 2 + 5 = 7. If, instead, we relocate consultant 1 to process p2 and then consultant 2 to process p3, this initially incurs cost ] (e) (f) 4. (a) the optimal solution, we minimize over the three choices.The optimality of these recursive steps can be seen from the cut-and-paste property. We assume that the requests are given in the array R[1..n] of indices of locations. In the notation above, it means that R[j] = r?? . The dynamic programming table is of size k3n and each entry takes constant time to fill in. Thus, the overall running time is O(k3n). Input: array of integers M[1..k] describing motion sickness of types of segments; array of non-negative integers E[1..k] describing excitement of types of segments; non-negative integer n. (b) 2 + 3 = 5, but all the future requests to p2 and p3 are processed for free. Thus, greedy solution is not optimal. The dynamic programming table is indexed by two indices: first index is a triple (i1, i2, i3) with i1, i2, i3 ? {1, 2, . . . , k} which indicate that consultants are present at locations pi1 , pi2 , pi3 , and the second index is j which indicates the prefix of the request sequence. The semantic array is defined as follows: D[(i1, i2, i3), j] = the cheapest way of processing requests r1, r2, . . . , rj with the three consultants beginning at p1 and ending at locations pi1 , pi2 , pi3 , respectively.The overall answer to the problem is stored in min1≤i1,i2,i3≤k D[(i1, i2, i3), n]. While request r refers to the location of some client, we use notation r?? to refer to the index of jj theclientr,i.e.,ifr =p thenr?? =l. jjlj Base case is when j = 0 then D[(i1, i2, i3), 0] = dist[1, i1] + dist[1, i2] + dist[1, i3] for all i1, i2, i3 ? {1,...,k}.The general case is for j ≥ 1 then we have:If rj is one of the pi1 , pi2 , pi3 then D[(i1, i2, i3), j] = D[(i1, i2, i3), j ? 1]. Otherwise, (c) (d) What is the cheapest way of D[(i ,r??,i ),j?1]+dist[r??,i ], 1j3 j2 D[(i ,i ,r??),j?1]+dist[r??,i ]). 12j j3 processing r1, . . . , rj with consultants ending up atmust travel D[(i ,i ,i ),j]=min(D[(r??,i ,i ),j?1]+dist[r??,i ], 123 j23 j1 pi1 , pi2 , pi3 ? When j = 0 then this is equivalent to saying that the consultants to pi1 , pi2 , pi3 from their initial locations 1, 1, 1. The cost of doing it is dist[1, i1] + dist[1, i2] + dist[1,i3], so this explains the base case. When j > 0 then there are two cases. Case 1: when rj is one of the locations pi1 , pi2 , pi3 . Then we can take the cheapest way of processing requests r1, r2, . . . , rj?1 and consultants ending up in pi1 , pi2 , pi3 and then the request rj is processed for free since we already have a consultant there. Case 2: when rj is not one of the locations pi1 , pi2 , pi3 . Suppose that consultant 1 was responsible for processing rj in the cheapest solution to the subproblem. It means that prior to relocating to pi1 the consultant was at rj to process that request. Thus, the optimal solution consists of processing requests r1, r2, . . . , rj?1 and ending in positions (rj , pi2 , pi3 ), processing request rj , and thenrelocatingconsultant1top . ThecostofthisisgivenbyD[(r??,i ,i ),j?1]+dist[r??,i ]. i1 j23 j1 Similar expressions are obtained when consultant 2 or consultant 3 is responsible for processing rj. Since we do not know a priori which of the consultants is responsible for processing rj in j locations procedure MinimizeTravelCost(dist[1..k][1..k],R[1..n]) Initialize array D[1...k, 1..k, 1..k, 0..n]fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo D[i1, i2, i3, 0] ? dist[1, i1] + dist[1, i2] + dist[1, i3] for j = 1 to n do fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo if R[j]=i1 orR[j]=i2 orR[j]=i3 then D[i1, i2, i3, j] ? D[i1, i2, i3, j ? 1] else D[i1, i2, i3, j] ? min(D[R[j], i2, i3, j dist[R[j], i2], D[i1, i2, R[j], j ? 1] + dist[R[j], i3]) r?∞fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo r ? min(r, D[i1, i2, i3, n]) return r ? 1] + dist[R[j], i1], D[i1, R[j], i3, j ? 1] + Output: maximum total excitement obtainable by a roller coaster consisting of n segments with motion sickness between 0 and 100 at all times. If such a roller coaster is impossible, the output is ?∞. (b) The array is indexed by two indices: i ? {0,1,...,n} and m ? {0,1,2,...,100}. D[i, m] = maximum total excitement of a roller coaster consisting of i segments with motion sickness between 0 and 100 at all times andexactly m at the end of i segments The overall answer is given by max0≤m≤100 D[n, m]. (c) D[0, 0] = 0 D[0,m] = ?∞ for m ? {1,...,100} D[i, m] = max D[i ? 1, m ? M[j]] + E[j] j?[k]:0≤m?M[j]≤100 Where the max returns ?∞ if there is no index j such that 0 ≤ m ? M[j] ≤ 100. 4. (d)  Maximum excitement roller-coaster of length i with motion sickness m at the end (if it can be built) contains some segment of type j as the last segment and a maximum excitement roller- coaster of length i ? 1 with motion sickness m ? M[j] at the end (by cut-and paste property). The last segment then gives excitement E[j] and the excitement accumulated by the first i ? 1 segments is given by D[i ? 1, m ? M[j]]. Since we do not know the value of j a priori, we optimize over all choices of j that are feasible, i.e., maintain motion sickness between 0 and 100. 5. (e)  The array contains O(n) entries, and each entry takes O(k) time to fill in. Thus, the overall running time would be O(nk). Jasmanpreet Kaur Bedi40231120Q1. a) Consider Huffman coding problem where character frequencies are f1, f2, . . . , fn. Prove the following statement by induction on n:If f1>∑_(i=2)^n?fi,  then character 1 receives codeword of length 1Prove your answer.1. (a) COMP 6651: Solutions to Assignment 2 Fall 2022Submission through Moodle is due by October 16th at 23:55 Claim: If f1 > Pni=2 fi then character 1 receives codeword of length 1 in Huffman coding problem. Proof by induction on n:Base case n = 2: in this case both characters receive codewords of length 1, so the claim is trivially true. Inductive assumption: assume that for all inputs with n ≥ 2 characters such that f1 > Pni=2 fi character 1 receives codeword of length 1 in Huffman coding problem. Inductive step: suppose we are given n + 1 characters with frequencies satisfying f1 > Pn+1 fi. i=2 The first step of the Huffman algorithm is that it merges the two characters of lower frequencies together. These two characters cannot be character 1, since we have at least three characters in total (i.e., n+1 ≥ 3) and f1 has highest frequency. Without loss of generality assume that lowest frequency characters are f and f (otherwise, we can reindex the characters). Let f?? denote n n+1 i the new frequencies after the merge operation. That is, we have f?? = f for i ? {1,2,...,n?1} ii and f?? = f + f . Observe that the new frequencies satisfy the inductive assumption, that n n n+1 is, f?? > Pn f??, since Pn f?? = Pn+1 f and f?? = f . Thus, by inductive assumption, the 1i=2i i=2ii=2i11 optimal solution to the new frequencies assigns character 1 codeword of length 1. According to Huffman’s algorithm, the solution to the original problem is obtained from the solution to the new frequencies by expanding the node corresponding to f?? to have two children corresponding n to frequencies fn and fn+1. Clearly, this does not affect the codewords of characters 1,...,n?1. Thus, if character 1 had codeword of length 1 in the solution to the new frequencies, then it also has codeword of length 1 in the solution to the original frequencies. The claim is TRUE. Suppose for contradiction that x is a character with codeword of length 1. Then during the second to last iteration of Huffman’s algorithm, the priority queue must have contents: f?? ≤ f?? ≤ f , abx where a and b are subtrees containing all the other characters (note that if we have f?? ≤ f ≤ f?? axb or f ≤ f?? ≤ f?? then x will be merged into subtree a and won’t get codeword of length 1). Since xab 2. (a) The input is given as an array of reals A[1..n]. First, sort the input points in non-decreasing order. Thus, we have A[1] ≤ A[2] ≤ · · · ≤ A[n] after the sorting operation. Pick the first point A[1] and include the interval [A[1], A[1] + 1] into the solution. Disregard the points covered by this interval, and repeat the procedure by picking the next uncovered point and introducing the unit length interval with that point as the leftmost point of the interval. Continue, until all the points are covered. (b) f < (1/3)Pn f it means that f??,f?? < (1/3)Pn f and f?? +f?? +f < (1/3)Pn f + x j=1j ab j=1j abx j=1j (1/3) Pnj =1 fj + (1/3) Pnj =1 fj = Pnj =1 fj , so the sum of all frequencies of characters is strictly less than Pnj=1 fj, which is a contradiction. (b) procedure CoverPoints(A[1..n]) Sort A in non-decreasing order Initialize solution set of intervals S ? ? i ? 1while i ≤ n do S ? S ? {[A[i], A[i] + 1]}while i + 1 ≤ n and A[i + 1] ≤ A[i] + 1 do i?i+1 i?i+1 return S ? keeps track of the next uncovered point 3. (c) For the following proof suppose that the input array is already sorted A[1] ≤ A[2] ≤ · · · ≤ A[n]. We use the standard greedy loop invariant. Let Si denote the solution obtained by greedy on the first i entries of the array A. (LI): Si can be extended to an optimal solution to the overall instance. Proof by induction on i: Base case i = 0: The solution set S0 is empty and an empty solution can be extended to an optimal solution to the overall instance. Inductive assumption: Assume that for some i ≥ 0 the partial greedy solution Si can be extended to some optimal solution OPT to the overall instance. Inductive step: Consider the partial greedy solution Si+1 on the first i+1 elements. We consider the different cases: Case 1: A[i+1] is covered by one of the intervals in Si. Then Si+1 = Si, by inductive assumption Si can be extended to OPT, therefore so can Si+1. Case 2: A[i + 1] is not covered by one of the intervals in Si. Thus, Si+1 = Si ? {[A[i + 1], A[i + 1]+1]}. Since extension of Si to an optimal solution OPT must cover point A[i+1] and none of the intervals in Si cover A[i+1], there must be some interval I ? OPT such that A[i+1] ? I. If I = [A[i+1],A[i+1]+1] then OPT is also an extension of Si+1 and we are done. If I = [r,r+1] is some other interval covering point A[i + 1], then we can replace it to define a new extension OPT = (OPT \ {I}) ? {[A[i + 1],A[i + 1] + 1]}. We claim that OPT is an optimal extension ]] of S . First observe that |OPT| = |OPT|, thus, the number of intervals in OPT is optimal. i+1 ]] Moreover, we can see that intervals in OPT must cover all the points, since the points A[1..i] ] ] are covered by S and S ? OPT. Moreover, if some point A[j] with j ≥ i + 1 was covered by ii I in OPT then it is covered by [A[i + 1],A[i + 1] + 1] in OPT. Since A[j] being covered by I with j ≥ i+1 implies that A[i+1] < A[j] < r+1 < A[i+1]+1, due to ordering of points and algorithm selecting the rightmost unit-length interval covering A[i + 1]. (d) The sorting operation can be done with MergeSort, for example, in time O(nlogn). The while loop iterates over the array A and does constant amount of work per each entry in A. Thus, the entire amount of work done by the outer while loop is O(n). The overall running time is dominated by the sorting operation and is, therefore, O(n log n). (a) Consider the input with 3 clients located on the line at positions p1 = 1, p2 = 3, p3 = 4. Since clients are located on the line, we have dist[i, j] = |pi ? pj |. Consider the request sequence: p2, p3, p2, p3, p2, p3. The greedy algorithm relocates one of the consultants from p1 to p2 at cost 2 and then this consultant is always the closest for all future requests to p2 and p3 incurring cost 1 for each subsequence request. Thus, the overall cost is 2 + 5 = 7. If, instead, we relocate consultant 1 to process p2 and then consultant 2 to process p3, this initially incurs cost ] (e) (f) 4. (a) the optimal solution, we minimize over the three choices.The optimality of these recursive steps can be seen from the cut-and-paste property. We assume that the requests are given in the array R[1..n] of indices of locations. In the notation above, it means that R[j] = r?? . The dynamic programming table is of size k3n and each entry takes constant time to fill in. Thus, the overall running time is O(k3n). Input: array of integers M[1..k] describing motion sickness of types of segments; array of non-negative integers E[1..k] describing excitement of types of segments; non-negative integer n. (b) 2 + 3 = 5, but all the future requests to p2 and p3 are processed for free. Thus, greedy solution is not optimal. The dynamic programming table is indexed by two indices: first index is a triple (i1, i2, i3) with i1, i2, i3 ? {1, 2, . . . , k} which indicate that consultants are present at locations pi1 , pi2 , pi3 , and the second index is j which indicates the prefix of the request sequence. The semantic array is defined as follows: D[(i1, i2, i3), j] = the cheapest way of processing requests r1, r2, . . . , rj with the three consultants beginning at p1 and ending at locations pi1 , pi2 , pi3 , respectively.The overall answer to the problem is stored in min1≤i1,i2,i3≤k D[(i1, i2, i3), n]. While request r refers to the location of some client, we use notation r?? to refer to the index of jj theclientr,i.e.,ifr =p thenr?? =l. jjlj Base case is when j = 0 then D[(i1, i2, i3), 0] = dist[1, i1] + dist[1, i2] + dist[1, i3] for all i1, i2, i3 ? {1,...,k}.The general case is for j ≥ 1 then we have:If rj is one of the pi1 , pi2 , pi3 then D[(i1, i2, i3), j] = D[(i1, i2, i3), j ? 1]. Otherwise, (c) (d) What is the cheapest way of D[(i ,r??,i ),j?1]+dist[r??,i ], 1j3 j2 D[(i ,i ,r??),j?1]+dist[r??,i ]). 12j j3 processing r1, . . . , rj with consultants ending up atmust travel D[(i ,i ,i ),j]=min(D[(r??,i ,i ),j?1]+dist[r??,i ], 123 j23 j1 pi1 , pi2 , pi3 ? When j = 0 then this is equivalent to saying that the consultants to pi1 , pi2 , pi3 from their initial locations 1, 1, 1. The cost of doing it is dist[1, i1] + dist[1, i2] + dist[1,i3], so this explains the base case. When j > 0 then there are two cases. Case 1: when rj is one of the locations pi1 , pi2 , pi3 . Then we can take the cheapest way of processing requests r1, r2, . . . , rj?1 and consultants ending up in pi1 , pi2 , pi3 and then the request rj is processed for free since we already have a consultant there. Case 2: when rj is not one of the locations pi1 , pi2 , pi3 . Suppose that consultant 1 was responsible for processing rj in the cheapest solution to the subproblem. It means that prior to relocating to pi1 the consultant was at rj to process that request. Thus, the optimal solution consists of processing requests r1, r2, . . . , rj?1 and ending in positions (rj , pi2 , pi3 ), processing request rj , and thenrelocatingconsultant1top . ThecostofthisisgivenbyD[(r??,i ,i ),j?1]+dist[r??,i ]. i1 j23 j1 Similar expressions are obtained when consultant 2 or consultant 3 is responsible for processing rj. Since we do not know a priori which of the consultants is responsible for processing rj in j locations procedure MinimizeTravelCost(dist[1..k][1..k],R[1..n]) Initialize array D[1...k, 1..k, 1..k, 0..n]fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo D[i1, i2, i3, 0] ? dist[1, i1] + dist[1, i2] + dist[1, i3] for j = 1 to n do fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo if R[j]=i1 orR[j]=i2 orR[j]=i3 then D[i1, i2, i3, j] ? D[i1, i2, i3, j ? 1] else D[i1, i2, i3, j] ? min(D[R[j], i2, i3, j dist[R[j], i2], D[i1, i2, R[j], j ? 1] + dist[R[j], i3]) r?∞fori1 =1tokdo fori2 =1tokdo fori3 =1tokdo r ? min(r, D[i1, i2, i3, n]) return r ? 1] + dist[R[j], i1], D[i1, R[j], i3, j ? 1] + Output: maximum total excitement obtainable by a roller coaster consisting of n segments with motion sickness between 0 and 100 at all times. If such a roller coaster is impossible, the output is ?∞. (b) The array is indexed by two indices: i ? {0,1,...,n} and m ? {0,1,2,...,100}. D[i, m] = maximum total excitement of a roller coaster consisting of i segments with motion sickness between 0 and 100 at all times andexactly m at the end of i segments The overall answer is given by max0≤m≤100 D[n, m]. (c) D[0, 0] = 0 D[0,m] = ?∞ for m ? {1,...,100} D[i, m] = max D[i ? 1, m ? M[j]] + E[j] j?[k]:0≤m?M[j]≤100 Where the max returns ?∞ if there is no index j such that 0 ≤ m ? M[j] ≤ 100. 4. (d)  Maximum excitement roller-coaster of length i with motion sickness m at the end (if it can be built) contains some segment of type j as the last segment and a maximum excitement roller- coaster of length i ? 1 with motion sickness m ? M[j] at the end (by cut-and paste property). The last segment then gives excitement E[j] and the excitement accumulated by the first i ? 1 segments is given by D[i ? 1, m ? M[j]]. Since we do not know the value of j a priori, we optimize over all choices of j that are feasible, i.e., maintain motion sickness between 0 and 100. 5. (e)  The array contains O(n) entries, and each entry takes O(k) time to fill in. Thus, the overall running time would be O(nk). Answer:1. Base Case –for n=2 (trivial)If n=2 then there are only two characters two be encoded and both f1, f2 receive a codeword of length 1.  2. Inductive Assumption – Assume that the statement is true for some n=k, where k ? 2If f1>∑_(i=2)^(n=k)?fi, then character 1 receives a codeword of length 1 is true for some n=k.If f1> f2+f3+f4+….+fk3. Inductive Step –To prove the statement true for all n, we will try to prove that the statement is true for some n=k+1.We want to prove:If f1>∑_(i=2)^(n=k+1)?fi, then character 1 receives a codeword of length 1 is true for some n=k+1.Consider the pseudocode for Huffman coding:??????????????(?? 1..?? )Initialize min-priority queue ?? to consist of elements ?? with priority field ??. ???????? = ??[??] for ?? = 1 to ?? ? 1 allocate a new node ????. ???????? ? ?? ? ???????????????????? ????. ??????h?? ? ?? ? ????????????????????(??) ??. ???????? ? ??. ???????? + ??. ???????? ????????????(??, ??) Return ????????????????????(??) In Huffman coding, the characters with the minimum frequency are always combined first, the sum of their frequencies then adds up to become another node. The codeword for a letter is the sequence of edge labels on the simple path from the root to the letter.Suppose some ith and (i+1)th nodes have the least frequency,Their value is combined first, and another node is created with value fi + fi+1Further the minimum value is found again, now considering the node with value fi + fi+1 There can be two cases on introducing a node k+1. Case 1: f1>fk+1As f1> f2+f3+f4+….+fk +fk+1 ,thus individually F1>f2, f1>f3, f1>f4……. F1>fk, f1>fk+1? i ?(2,3,…k,k+1), f_1>f_iThus character with frequency f1 will not be extracted as the minimum and combined with any other node until only two nodes are remaining as shown below.Therefore, it can be noted that In the case that f1>∑_(i=2)^(k+1)?fi, the character 1 with frequency f1 will always receive a codeword of length 1.Case 2: fk+1>f1In this case, the min priority queue (used for maintaining the characters and frequencies in a sorted order) will re-adjust and fk+1 will become the new character with the highest frequency and can be called character f1’.       f1’>f1> f2+f3+f4+….+fk       	f1’ will become character 1 and will receive a codeword of length 1.	Hence Completing the proof by induction.Q1 b) Consider Huffman coding problem where character frequencies are f1, f2, . . ., fn. True or false?If for all i, it holds that f_i<1/3 ∑_(j=1)^n?f_j then there is guaranteed to be NO codeword of length 1.Prove your answer.  Answer:The statement given is True .		 		?i, f_i<1/3 ∑_(j=1)^n?f_j      This means that        f1< 1/3(f1+ f2+f3+f4+….+fn)      f2< 1/3(f1+ f2+f3+f4+….+fn)      f3< 1/3(f1+ f2+f3+f4+….+fn)          .          .          .      fn< 1/3(f1+ f2+f3+f4+….+fn)		 It can be calculated on adding f1and f2 that f1+f2 <2/3(f1+ f2+f3+f4+….+fn) Consider the Huffman coding algorithm, the characters with the minimum frequency are always combined first, the sum of their frequencies then adds up to become another node. The codeword for a letter is the sequence of edge labels on the simple path from the root to the letter.Suppose we have a codeword of length 1, then there would be some character say z with frequency fz which would have a frequency greater than all the other elements combined.It is given that : fz< 1/3(f1+ f2+f3+f4+….+fn) .Equation  ? can be extended further to         Sum of n-1 nodes < (n-1)* 1/3(f1+ f2+f3+f4+….+fn) .For Fz to get a codeword of length 1, it is necessary that it remains until all other characters have merged into one single node at the end which means it should not be combined at any step with any other node. Thus at any point it’s frequency needs to be greater than the individual character frequencies as well as the sum of their frequencies up until the last step where there are only two nodes remaining.In the given question, this is not the case as any point Fz has a frequency < 1/3(f1+ f2+f3+f4+….+fn) .The moment the sum of any two or multiple nodes crosses  1/3(f1+ f2+f3+f4+….+fn), the aglorith of huffman coding will pick Fz for combining with other nodes and it will not receive a codeword of length 1.Consider a case where there are only four nodes, X, Y,W and Z. Suppose that Z gets a codeword of length 1. For the character with frequency fz to get a codeword of length 1Fz >Fy, Fz>Fx, Fz>Fw And Fz> Fx + FyBut all the frequencies are <1/3(f1+ f2+f3+f4) On combining any two sum becomes <2/3(f1+ f2+f3+f4). Fz can become less than the sum of x and y and thus algorithm will pick and combine it with the last element Fz hence not giving it a codeword of length 1. This becomes a contradiction. Therefore a codeword of length 1 is not possible.Q2. Given a set of points {a1, a2, . . . , an} on a line, you want to find a minimum sized set of closed unit intervals {[pi, pi + 1] | 1 ≤ i ≤ k} that contain all the points. Give an efficient greedy algorithm for this problem. Answer:a) Algorithm Description in plain EnglishTo get the minimized set closed unit intervals, the devised greedy algorithm takes the sorted in increasing order array of points as input.It maintains a set for the minimum closed unit intervals.It selects the minimum element that has not belonged to any closed unit interval until that point. Suppose the element is at ith index. It considers a closed interval from that point pi to pi+1.It then removes all the points from consideration belonging to the closed interval [pi, pi+1] and adds the closed interval to the maintained setThis process is repeated until all the elements in the array have been removed.b) PseudocodeA- Sorted Array of pointsClosedUnitIntervals (Array A[1..n])	Set SIndex_next=1While (Index_next<=n){P=A[Index_next]Interval_start = A[Index_next]Interval_end= A[Index_next]+1Push [Interval_start, Interval_end] into the maintained set SWhile (A[i] ? interval_start and A[i] <=interval.end  and Index_next<=n)	Index_next++      }Return Set Sc) Proving correctnessSuppose that our greedy algorithm outputs a solution with p unit-length closed intervals: I1, I2, ..., IX. Suppose that there exists an optimal solution O1, O2,O3…OyIn order to prove that the greedy algorithm is correct, we will prove that the greedy solution covers as many intervals and points as the Optimal Solution i.e. for 1≤ k ≤ min(x, y) where x is the minimum number of intervals in the greedy solution and y is the minimum number of intervals in the optimal solution.Proving this using the principles of Induction.1. Base Case: k=1 (trivial)It is assumed that Interval 1 in the greedy solution that covers the point p1 covers all the points covered by the optimal solution2. Inductive Assumption: Suppose the statement is true for k = 1..p for some p ≥ 1. Thus I1….Ip covers as many or more points than O1 …Op3. Inductive step: We need to prove that the statement is true for k = p+ 1.Say that the first point that is covered by greedy is Ip+1 and the first point covered by optimal is Op+1 From the step 2- inductive assumption, we have I1…. Ip covers as many points as possible or more than O1…. Op Thus, We have Ip+1 >=  Op+1Therefore, Ip+1’s ending position will be greater than or equal to Op+1’s ending position. Therefore, we can conclude that I1….Ip+1 covers as many or more points than O1 …Op+1d) Running Time of AlgorithmIf the array of points is not already sorted then it takes O(n log n) time complexity to sort the array A of points.There are n comparisons taking place while comparing an interval with the points in the arrayOther operations take constant time for executionThus the total time complexity is:a) In case of a sorted array – O(n)b) In case of an unsorted array – O (n logn) [including the overhead for sorting]Q3. You are running a consulting company. You have k clients located at positions p1, . . . , pk and 3 consultants which all are initially located at position p1. Let dist[i,j] denote the distance between positions pi and pj. You are also given a sequence of requests from the clients r1,r2,...,rn. Each request ri ? {p1, . . . , pk} specifies a position of the client requiring assistance. To process a request ri you need to relocate a consultant to the request’s position. You wish to minimize the total distance travelled by the consultants while all requests are processed in the order that the requests are given. In this question you will design an efficient dynamic programming algorithm that given the distance function and the request sequence computes the minimum distance jointly travelled by the consultants to process all the requests in the given order. Answer:Ci= consultant I [1,2,3]a) Suppose that in the given example of distance function in the assignment, 	If the input sequence is p4, p2, p5.Initially all the consultants are at p1. After r1, the consultant c1 moves to p4 and c2, c3 remain at p1. At R2, c1 is at distance of 2 from p2 at p4 and c2, c3 are at distance of 3 from p2 at p1. The greedy algorithm moves c1 from p4 to p2 with distance 2 as it selects the consultant with the minimum distance or closest consultant to the request. The next request is at p5. Now c2, c3 are at a distance of 6 from p5 at p1 and c1 is at a distance 3 from p5 at p2.The total distance output by the greedy algorithm that processes each request, relocates consultant closest to the request to process it is:Moving consultant c1 to p4, p2, p5 distance becomes d[p1,p4]+d[p4,p2]+d[p2,p5] = 5+2+3 = 10Whereas if the algorithm moved c2 or c3 from p1 to p2 for the second request instead of c1 moving to p2, then the sequence would be:Move c1 to p4, then move c2 to p2, moving c1 to p5, the distance becomesd[p1,p4]+d[p1,p2]+d[p4,p5]=5+3+1=9The optimal solution for this sequence would be 9 whereas the greedy solution gave an output of 10. b) Semantic array for a dynamic programming algorithm.A 3 Dimensional array of size n*k*3Where n is the number of requests. K is the number of points and 3 is the number of consultants which remains constant.Dp[i][k][j] = distance travelled by j’th consultant to service i’th request from point kc) Computational array :Dp[i][k][j]= min(dp[i-1][k][j]+dist[i,k] ? k in [0,number of points given], ? j in{1,2,3})Each cell will represent the distance travelled by a consultant to travel to a point if it was called for service from any other point.d) Semantic Array = Computational Array At each value of request, point and consultant, the computational array updates the value of distance for a consultant to reach that request from point k.Dp[n][k][j] for each consultant has the total distance travelled. We select the minimum value for each consultant from the values with the index of the last request.After all loops are traversed, the dp array will be full of all possibilities for all consultants. To find the minimum distance we just need to find the minimum distance value for each consultant at the last request and sum it up.Min(Dp[n][k][1])+ Min(Dp[n][k][2])+ Min(Dp[n][k][3]) = final answer			Semantic arrays	e) The complexity will be O(n*k*3)The outer loop for number of requests runs n times, the loop for the number of points runs k times for calculating the distance to reach the request from each point if a consultant c[i] reached there at any previous request.And 3 for each consultant.Q4. You are designing a roller coaster for an amusement park. You have access to an infinite supply of roller coaster segments of k different types. Each type is described by two parameters (ei,mi), where ei ? Z≥0 is how much one segment of this type adds to excitement and mi ? Z is how much one segment of this type adds to (or subtracts from, since we allow negative mi) motion sickness. Your job is to decide which segments to place one after another to form a roller coaster consisting of n segments in total. You wish to maximize total excitement; however, you cannot just place one exciting segment after another, as this will make many riders motion sick. At the start of the roller coaster excitement is 0 and motion sickness is 0, and these two parameters accumulate additively. The goal is to maximize overall excitement while keeping the accumulated motion sickness between 0 and 100 (inclusive) during the entire ride. Design an efficient dynamic programming algorithm for this. Hint: consider subproblems indexed by two parameters i and m, where 0 ≤ i ≤ n and 0 ≤ m ≤ 100. Answer:a. Input: n segmentsk types of roller coasters Motion sickness array MExcitement array EOutput:Overall maximized excitement while maintaining the motion sickness between 0 and 100b. Semantic ArrayDp is a 2-d array of size n * m i.e size 0 ≤ i ≤ n and 0 ≤ m ≤ 100.Dp[i][j] = the excitement at ith segment with j value of motion sickness c. Computational arrayDp[i,j+M[k]]=max(E[k] + Dp[i-1][j] such that j+M[k] is between [0,100] ,Dp[i-1][j]) i= segment  j= previous motion sickness k= which distinct roller coaster is being consideredThe 2D Dp array stores the excitement at ith segment with a specific value of Motion sickness. It stores the maximum value of excitement after considering whole set of possible solutions. At every point, there are multiple alternatives, to decide among the rides considering every part of the previous combinations.d. Semantic Array = computational arraySemantics represent the meaning. Here the semantic array represents the maximum value of excitement at the i’th segment considering the k’th roller coaster.At any point the computational array visits the previous calculated values and adds the value of excitement and motion sickness to it.If the value of motion sickness remains within constraints i.e 0 ≤ m ≤ 100then it adds the value of excitement and checks with other possible solutions using other roller coaster rides if a better value is possible. It updates the dp array with all feasible solutions not just the one returning the maximum value at that instant as it is possible that a suboptimal solution at point I gets mixed with a value at j’th index and returns the most optimal value. After considering all optimal and sub optimal values of excitement at the intermediate points, the dp array returns maximum possible excitement with restricted motion sickness among n rides at the end.The semantic array represents excitement value at I’th segment with j value of motion sickness. Thus, the computational array is helping us essentially calculate and justify the value stored in the computational array. Actually, They are describing and representing the same things. Therefore, semantic array=computational array.e. Running timeBased on the computational array, the algorithm will run k * n times, where k represents the number of roller coaster rides and n represents the number of segments.Since at every roller coaster i, we have an option to select one out of the k roller coasters, the loop runs k times and i can range till n . foOpposable thumbs are such an ingrained part of humans’ day-to-day life that most do not pay them much notice. However, they could be a matter of life or death for our ancestors. Per Handwerk (2021), opposable thumbs allowed earlier humans to survive and thrive, enhancing their ability to create tools and weapons to kill large animals.Opposable thumbs are such an ingrained part of humans’ day-to-day life that most do not pay them much notice. However, they could be a matter of life or death for our ancestors. Per Handwerk (2021), opposable thumbs allowed earlier humans to survive and thrive, enhancing their ability to create tools and weapons to kill large animals.Opposable thumbs are such an ingrained part of humans’ day-to-day life that most do not pay them much notice. However, they could be a matter of life or death for our ancestors. Per Handwerk (2021), opposable thumbs allowed earlier humans to survive and thrive, enhancing their ability to create tools and weapons to kill large animals.Opposable thumbs are such an ingrained part of humans’ day-to-day life that most do not pay them much notice. However, they could be a matter of life or death for our ancestors. Per Handwerk (2021), opposable thumbs allowed earlier humans to survive and thrive, enhancing their ability to create tools and weapons to kill large animals.Opposable thumbs are such an ingrained part of humans’ day-to-day life that most do not pay them much notice. However, they could be a matter of life or death for our ancestors. Per Handwerk (2021), opposable thumbs allowed earlier humans to survive and thrive, enhancing their ability to create tools and weapons to kill large animals.Opposable thumbs are such an ingrained part of humans’ day-to-day life that most do not pay them much notice. However, they could be a matter of life or death for our ancestors. Per Handwerk (2021), opposable thumbs allowed earlier humans to survive and thrive, enhancing their ability to create tools and weapons to kill large animals.Opposable thumbs are such an ingrained part of humans’ day-to-day life that most do not pay them much notice. However, they could be a matter of life or death for our ancestors. Per Handwerk (2021), opposable thumbs allowed earlier humans to survive and thrive, enhancing their ability to create tools and weapons to kill large animals.r every n there are k options , thus n*kdsflhasd;lff'z;Kfep9ufjd